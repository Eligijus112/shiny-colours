{
    "collab_server" : "",
    "contents" : "---\nheader-includes:\n  - \\usepackage[L7x]{fontenc}\n  - \\bibliographystyle{plainnat}\noutput:\n pdf_document: \n    fig_caption: yes\n    keep_tex: yes\n    number_sections: no\n    latex_engine: pdflatex\nmargin-left: 6.5in\nmargin-top: 9in\nfontsize: 12pt    \npapersize: A4\nfontfamily: palatino\n---\n\n```{r setup, include=FALSE}\nlibrary(plm)\nlibrary(RCurl)\nlibrary(dplyr)\nlibrary(plyr)\n# library(emibase)\nlibrary(plotrix)\n# library(mgcv)\nlibrary(reshape2)\nlibrary(readxl)\nlibrary(knitr)\nlibrary(rworldmap)\nlibrary(cshapes)\nlibrary(countrycode)\nlibrary(texreg)\nlibrary(ggplot2)\nlibrary(directlabels)\n# library(splines)\nlibrary(MASS)\nlibrary(TTR)\nlibrary(rsdmx)\nlibrary(httr)\nlibrary(splines)\nlibrary(xtable)\n# library(dynpanel)\nlibrary(devtools)\nlibrary(corrplot)\nsource('functions.R')\nlibrary(car)\nlibrary(tseries)\nlibrary(RefManageR)\nlibrary(forecast)\n```\n\n\\vskip 20pt\n\\centerline{\\bf \\large VILNIUS UNIVERSITY}\n\\bigskip\n\\centerline{\\large \\textbf{FACULTY OF MATHEMATICS AND INFORMATICS}}\n\\vskip 120pt\n\\centerline{\\bf \\Large \\textbf{BACHELOR THESIS}}\n\\vskip 50pt\n\\begin{center}\n{\\bf \\LARGE Tourism model in the Western world}\n\n\\vspace{4mm}\n\n\\end{center}\n\\vskip 120pt\n\\centerline{\\Large Eligijus Bujokas}\n\\vskip 120pt\n\\centerline{\\large \\textbf{VILNIUS 2017}}\n\\thispagestyle{empty}\n\n\\newpage\n\n\\begin{titlepage}\n\\centerline {\\bf \\large FACULTY OF MATHEMATICS AND INFORMATICS}\n\\centerline {\\bf DEPARTMENT OF MATHEMATICAL ANALYSIS}\n\\vskip 120pt\n\\large Scientific supervisor Vaidotas Zemlys-Balevičius, PhD \\underline{\\hskip 95pt}\n\\vskip 20pt\n\\large Reviewer Lina Dindienė, PhD \\underline{\\hskip 95pt}\n\\vskip 150pt\n\\end{titlepage}\n\n\\newpage\n\n\\begin{center}{\\large\\textbf{Turizmo modelis vakarų šalyse}}\\end{center}\n\\vspace{2\\baselineskip}\n\\begin{center}\\textbf{Santrauka}\\end{center}\n\n\\hskip 15pt  Šio darbo tikslas yra sudaryti turizmo modelį Vakarų Europos šalims bei Amerikai ir Kanadai. Naudojantis viešais pasaulinio banko (World Bank), OECD ir Merilando Universiteto duomenų bazės (the Department of Homeland Security Center of Excellence led by the Maryland University) duomenimis bandėme paaiškinti kasmetinius atvykusių turistų srautų procentinius pokyčius naudodamiesi procentiniais BVP vienam asmeniniui pokyčiais, teroro aktų skaičiaus pokyčiais, mokesčių paslaugoms pokyčiais, kasmetinių dirbamų valandų vidurkių pokyčiais, investicijų į infrastruktūrą pokyčiais bei pačių turistų srautų ankstinių pokyčiais. Ryšio nustatymui naudojome įvairaus tipo panelinius modelius. Išbandę įvairius kintamųjų ankstinius, pritaikę pažingsninį kintamųjų išmetimo (išmetant mažiausiai reikšmingą) metodą bei pašalinę išskirtis gavome, jog turistų srautų pokyčiams reikšmingą įtaką turi metinis vidutinis pradirbtų valandų skaičiaus pokytis, teroristinių įvykių skaičiaus pokytis, mokesčių paslaugų sektoriui pokytis (skaičiuojamas procentu nuo BVP) bei atvykusių turistų skaičiaus procentinio pokyčio ankstinys. Pasinaudoję visa išskaidymo informacija, kurią suteikia OECD duomenų bazė gavome, jog lyginant užsienio ir vietinę ekonomikas, reikšmingą įtaką turistų skaičiaus pokyčiams turi šalių, iš kurių atvyksta turistai, BVP vienam asmeniui pokyčiai. BVP vienam asmeniui pokyčiai šalyje, į kurią atvyksta turistai, nėra reikšmingi norint paaiškinti turizmo srautus. \n\n\\vspace{\\baselineskip}\n\\noindent\\textbf{Raktiniai žodžiai :}\n BVP, OECD, pasaulinis bankas, panelinis modelis, darbo valandos, terorizmas, turizmas, mokesčiai paslaugoms, investicijos į infrastruktūrą, tiesiniai modeliai.\n\n\\vspace{\\baselineskip}\n\\thispagestyle{empty}\n\n\\newpage\n\n\\begin{center}{\\large\\textbf{Tourism model in western countries}}\\end{center}\n\n\\vspace{2\\baselineskip}\n\\begin{center}\\textbf{Abstract}\\end{center}\n \\hskip 15pt  The aim of this paper is to construct a model to help explain the number of tourist arrivals in Western European countries and USA and Canada. By using public data from the World Bank, OECD and the Department of Homeland Security Center of Excellence led by the Maryland University's database we tried to explain the differences of tourist arrivals to a given country by using changes in GDP per capita, differences in terror attacks, differences in taxes on good and services, changes in investments to infrastructure, changes in average annual hours worked and the lags of changes of tourist arrivals. To identify the relationship we used various  panel models. After trying different lags of the variables, the step-wise elimination of variables algorithm and the elimination of outliers we have concluded that changes in annual hours worked, changes in terror attacks, changes in taxes on goods and services and the lag of percentage change in tourist flows all have a significant influence to the changes in tourism flows. Using the information provided by the OECD database on the decomposition of tourism flows we have found that the changes of tourism flows are influenced by the changes in GDP per capita of the countries from which the tourists arrive and not by the changes in GDP per capita in the destination country.\n\n\\vspace{\\baselineskip}\n\\noindent\\textbf{Key words :}\nGDP per capita, OECD, World Bank, panel model, hours worked, terrorism, tourism, taxes on goods and services, investments to infrastructure, linear models \n\\thispagestyle{empty}\n\n\\vspace{\\baselineskip}\n\n\\newpage\n\n\\tableofcontents\n\n\\thispagestyle{empty}\n\n```{r constants, include=FALSE}\nyears.to.survey <- 1995:2015\npath <- \"data/\"\n# regions <- read.csv(file=\"input/regions.csv\", stringsAsFactors = F)\ncreatedir(\"plots\")\n# createdir(\"input\")\ncreatedir(\"data\")\ncreatedir(\"output\")\n# devtools::install_url(\"http://cran.r-project.org/src/contrib/rprojroot_1.2.tar.gz\") ## MAY RESOLVE TROUBLESHOOTS\nknitr::opts_chunk$set(fig.pos = 'h')\n\nbib <- ReadBib(\"bibliography.bib\", check = FALSE)\nBibOptions(check.entries = FALSE, style = \"markdown\", bib.style = \"alphabetic\", cite.style = 'alphabetic')\n```\n\n```{r data download and reading it, include=FALSE, echo=F}\n# we will save this data to the 'data' folder\n# download.terror(years.to.survey, \"data/\") \n# dt <- read.terror(\"data/terror/\")\n# dt <- arrange(dt, Date)\n# na.index <- which(apply(dt, 1, function(x){ all(is.na(x)) }))\n# if(length(na.index)!=0) dt <- dt[-na.index, ]\n# write.csv(aggregate.terror.by.country(dt), file=\"input/terror raw data.csv\", na=\"\", row.names=F)\n\ncountries <- c(\"France\", \"United Kingdom\", \"United States\", \"Canada\", \"Germany\", \"Spain\", \"Portugal\", \"Netherlands\", \"Austria\", \"Italy\", \"Belgium\")\nall.terror <- read.csv(\"data/terror2/all terror.csv\", stringsAsFactors = F)\nall.terror <- all.terror[all.terror$iyear > 1995 & all.terror$country_txt %in% countries, c(\"iyear\", \"country_txt\")]\n\ndt.terror <- ddply(all.terror, ~country_txt + iyear, function(xframe){\n  \n  xframe <<- xframe\n  \n  xframe$total <- nrow(xframe)\n  \n  return(xframe[nrow(xframe), ])\n})\n \ndt.terror <- ddply(dt.terror, ~country_txt, function(xframe){\n  \n  xframe <<- xframe\n  \n  miss <- setdiff(paste(1995:2015), xframe$iyear)\n  \n  if(length(miss)!=0){\n    \n    \n    add <- matrix(ncol=3, nrow=length(miss)) %>% as.data.frame\n    names(add) <- names(xframe)\n    add$iyear <- miss\n    add$country_txt <- xframe$country_txt[1]\n    add$total <- 0\n    \n    xframe <- rbind(xframe, add) %>% arrange(iyear)\n  }\n  \n  return(xframe)\n})\n  \ndt.terror <- rename(dt.terror, c(\"iyear\" = \"Date\", \"country_txt\" = \"Country\", \"total\" = \"Terror.attacks\"))\nwrite.csv(dt.terror, \"input/terror raw data.csv\", row.names=F, na=\"\")\n  \n## Tourism data\n# \n# dt.tour <- download.tourism(\"data/\")\n# write.csv(dt.tour, file=\"input/total arrivals.csv\",  na=\"\", row.names=F)\n\n## Economic data\n\ndt.eco <- download.economy(\"data/\")\ndt.eco <- make.economy.great.again(dt.eco)\nwrite.csv(dt.eco, file=\"input/gdp.csv\", na=\"\", row.names=F)\n\n## OECD data on hours worked\n\ndt.oecd <- get_dataset(\"ANHRS\", path=\"data/\")\ndecode  <- get_decoder(\"data/\")  \nwrite.csv(dt.oecd, file=\"input/hours.csv\", na=\"\", row.names=F)\n\n```\n\n```{r data input, include=FALSE, echo=F}\n\ndecoder  <- read.csv(\"input/decoder.csv\", stringsAsFactors = F)\nstruct <- read.csv(\"input/tourism structure.csv\", stringsAsFactors = F) %>% get.cols\nflows  <- read.csv(\"input/receipts.csv\", stringsAsFactors = F) %>% get.cols\nterror <- read.csv(\"input/terror raw data.csv\", stringsAsFactors = F)\ntax    <- read.csv(\"input/tax.csv\", stringsAsFactors = F) %>% filter(MEASURE==\"PC_TOT_TAX\") \ngdp    <- read.csv(\"input/gdp.csv\", stringsAsFactors = F) %>% rename(c(\"CountryName\" = \"Country\"))\nhours  <- read.csv(\"input/hours.csv\", stringsAsFactors = F) %>% format.hours(decoder)\nInv    <- read.csv(\"input/infrastructure.csv\", stringsAsFactors = F) %>% filter(SUBJECT==\"INLAND\")\ntotal.arrivals <- read.csv(\"input/total arrivals.csv\", stringsAsFactors = F)\nreceipts <- read.csv(\"input/receiptsUS.csv\", stringsAsFactors = F)\n\n```\n\n```{r formating input for the big model, include=FALSE, echo=F}\n\n## Merging everything to one data frame\n\nmaster.data <- merge(total.arrivals, terror)\ngdp.m <- gdp[, c(\"Country\", \"Date\", \"value\")] %>% rename(c(\"value\"=\"gdp\"))\nmaster.data <- merge(master.data, gdp.m)\n\ntax <- rename(tax, c(\"LOCATION\" = \"ï..LOCATION\"))\ntax <- tax[, c(\"ï..LOCATION\", \"TIME\", \"INDICATOR\",  \"Value\")]\ntax <- rename(tax, c(\"ï..LOCATION\" = \"Country\", \"INDICATOR\" = \"Indicator\", \"TIME\" = \"Date\"))\n  \ntax <- ddply(tax, ~Country, function(xframe){\n    \n  xframe <<- xframe\n  real.name <-  decoder[decoder$CountryCode==xframe$Country[1], \"CountryName\"]\n  if(length(real.name)==0) real.name <- xframe$Country[1]\n  xframe$Country <- real.name\n  return(xframe)\n    \n})\n  \ntax[tax$Country==\"Korea, Rep.\", \"Country\"] <- \"South Korea\"  \ntax[tax$Country==\"Korea\", \"Country\"] <- \"South Korea\" \n  \nInv <- rename(Inv, c(\"LOCATION\" = \"ï..LOCATION\"))\nInv <- Inv[, c(\"ï..LOCATION\", \"TIME\", \"INDICATOR\",  \"Value\")]\nInv <- rename(Inv, c(\"ï..LOCATION\" = \"Country\", \"INDICATOR\" = \"Indicator\", \"TIME\" = \"Date\"))\n  \nInv <- ddply(Inv, ~Country, function(xframe){\n    \n  xframe <<- xframe\n  real.name <-  decoder[decoder$CountryCode==xframe$Country[1], \"CountryName\"]\n  if(length(real.name)==0) real.name <- xframe$Country[1]\n  xframe$Country <- real.name\n  return(xframe)\n    \n})\n  \nInv[Inv$Country==\"Korea, Rep.\", \"Country\"] <- \"South Korea\"  \nInv[Inv$Country==\"Korea\", \"Country\"] <- \"South Korea\" \n\ntax.m <- tax[, c(\"Country\", \"Date\", \"Value\")] %>% rename(c(\"Value\"=\"tax\"))\nmaster.data <- merge(master.data, tax.m)\nInv.m <- Inv[, c(\"Country\", \"Date\", \"Value\")] %>% rename(c(\"Value\"=\"Investment\"))\nmaster.data <- merge(master.data, Inv.m)\nhours.m <- hours[, c(\"Country\", \"Date\", \"Value\")] %>% rename(c(\"Value\"=\"hours.worked\"))\nmaster.data <- merge(master.data, hours.m)\nmaster.data <- master.data[complete.cases(master.data), ]\n\nmaster.data <- ddply(master.data, ~Country, function(xframe){\n  \n  xframe <<- xframe\n  if(nrow(xframe)!=length(master.data$Date %>% unique())){\n    \n    xframe <- NULL\n    \n  }\n  \n  return(xframe)\n  \n})\n\nmaster.data <- master.data[master.data$Country %in% countries, ]\n\npdata <-  plm.data(master.data, index = c(\"Country\", \"Date\")) \nlog.vars <- c(\"Total.Arrivals\", \"gdp\", \"hours.worked\")\npdata[, log.vars] <- apply(pdata[, log.vars], c(1, 2), log)\n\npdata <- ddply(pdata, ~Country, function(xframe){\n  \n  xframe <<- xframe\n  xframe[, 3:dim(xframe)[2]] <- apply(xframe[, 3:dim(xframe)[2]], 2, function(x){\n  \n  return(c(NA, diff(x)))\n  \n  })\n  \n  return(xframe)\n  \n})\n\npdata <- pdata[complete.cases(pdata), ]\n```\n\\newpage\n\n\\setcounter{page}{1}\n\n\\section{Introduction}\n\n\\hskip 15pt Tourism is a collection of activities, services and industries which deliver a travel experience comprising transportation, accommodation, eating and drinking establishments, retail shops, entertainment businesses and other hospitality services provided for individuals or groups traveling away from home. According to UNWTO (United Nations World Tourism Organization)`r Citet(bib, 'UNWTO', .opts = list(cite.style = \"numeric\"))`:\n\n\\hskip 15pt $\\bullet$ 1 in 11 jobs worldwide are related to the tourism industry.\n\n\\hskip 15pt $\\bullet$ 10 percent of total world GDP is produced by tourism.\n\n\\hskip 15pt $\\bullet$ Tourism made up for about 7 percent of world's exports: 1.5 trillion US dollars.\n\n\\hskip 15pt $\\bullet$ In 2015 there were 1186 million tourists worldwide and this number is expected to grow up to 1.8 billion by 2030.\n\n\\hskip 15pt $\\bullet$ In 2015 the total receipts by tourists was about 1.26 trillion US dollars.\n\n```{r receipts, echo=F, fig.cap=\"Tourist receipts in the Western countries (World Bank data)\", fig.height=5, fig.width=7,  fig.pos=\"!ht\", fig.align=\"center\"}\n\n receipts <- receipts %>% rename(c(\"ï..Country.Name\" = \"CountryName\", \"Indicator.Name\" = \"Product\"))\nreceipts <- receipts[receipts$CountryName %in% countries, ]\n colnames(receipts) <- gsub(\"X\", \"\", colnames(receipts))\n\n sums <- apply(receipts[, paste(1960:2016)], 2, sum)\n\n sums <- sums[!is.na(sums)]/1000000000\n\n grid.frame(x=as.numeric(names(sums)), y=sums, xlab=\"Time\", ylab=\"Total receipts, billion US\", cex.lab=2)\n\n matplot(x=as.numeric(names(sums)), y=sums, pch=19, type=\"o\", col=\"dodgerblue1\", add=T, lwd=2)\n\n mtext(\"Total receipts from tourists in the selected countries\", col=\"salmon1\", line=1, cex = 2)\n```\n\n<!-- \\hskip 15pt From figure 1 it is clear to see that the trend of the total receipts from tourists in the western countries which were mentioned is increasing. It is likelly therefore that in the future receipts will only grow in absolute sense. -->\n\n\\hskip 15pt Acording to the World Economic Forum's report on tourism `r Cite(bib, 'WEC', .opts = list(cite.style = \"numeric\"), after=\" , pp. 19-20\")`,  in an increasingly protectionist context — one that is hindering global trade — the travel and tourism industry continues building bridges rather than walls between people, as made apparent by increasing numbers of people travelling across borders and\nglobal trends toward adopting less restrictive visa policies. The share of ideas and cultures is a welcoming trend in the contemporary world. More and more, governments around the world are realizing that, for the most part, barriers to travel are not making people\nand countries safer, but are hindering economic growth, job creation and tolerance between countries. With a growing “wanderlust”, there is a unique opportunity for many countries to benefit from the T&T industry while, at the same time, ensuring the security of borders and citizens. This trend is sustained by diverging underlying policies in trade and tourism. In 2016, destinations worldwide required 58% of the world’s population to obtain a visa prior to departure. In 2007 this number was 77%. \n\n\\hskip 15pt Furthermore, a report by the World Bank `r Cite(bib, 'WB', .opts = list(cite.style = \"numeric\"))` concludes that tourism provides opportunities for economic diversification and skills upgrading. The tourism sector provides a means by which local entrepreneurs can experiment with new products and test them on international markets in their home country before exporting. International tourists typically create demand for products and services which may not have already existed in the local market and also demand certain quality standards. Whilst these can be a challenge to meet in the short-term, tourism creates the market and the incentive to drive the process – leading to growth and improvement over time. \n\n\\hskip 15pt A study made by Ashley, Roe and Goodwin `r Cite(bib, 'pro.poor', .opts = list(cite.style = \"numeric\"))` concluded that the expansion of tourism sector has several positive effects for the poorest of the people in a country. According to the study, it does appear possible to ‘tilt’ the tourism sector at the margin, to expand opportunities for the poor. Diversification into culturally-based products, expansion of business linkages, redistribution of assets (equity, land) to the poor, and inclusion of their voice in tourism plans are long-term changes with potential for replication. Furthermore, the poor can provide tours, authentic souvenirs and such goods which do not require a higher education or a specific set of skills. By increasing demand for goods and services provided by the poor, and increasing their asset base is helping the unemployment to shrink and more and more people can break above the poverty line. \n\n\\hskip 15pt On the other side of the income scale, bussiness owners and investors also greatly benefit from the expansion of the tourism sector. A paper published by Stynes `r Cite(bib, 'eco.impact', .opts = list(cite.style = \"numeric\"))` concluded that tourism can often inflate the cost of housing and retail prices in popular areas for tourists, frequently on a seasonal basis which in turn can bring profits to investors and land owners. Additionally, an increase in the number of tourists staying overnight in hotels would directly yield increased sales in the hotel sector hence giving dividents to hotel owners. The additional hotel sales and associated changes in hotel payments for wages and salaries, taxes, and supplies and services are direct effects of the tourist spending. There are also the indirect effects of a positive change of tourism flows: the production changes resulting from various rounds of re-spending of the hotel industry's receipts for example in other backward-linked industries (i.e., industries supplying products and services to hotels). Styne concludes that there is an evident \"trickle down\" effect of the receipts generated by tourism for the whole economy which in turn benefits every member of the society. \n\n\\hskip 15pt We can see that countries benefit from tourism flows both economically and socially. In this paper we want to find which economic and social variables significantly influence tourism demand in France, United Kingdom, USA, Canada, Germany, Spain, Portugal, Netherlands, Austria, Italy and Belgium. These group of countries can be defined as the Western world or western countries. The findings of the significant variables may help governments in deciding which policies to adapt in order to grow the tourism sector. \n\n\\hskip 15pt All of the graphics, models and other calculations in this thesis are created using the statistical package R `r Cite(bib, 'R', .opts = list(cite.style = \"numeric\"))`.\n\n\\newpage\n\n\\section{Literature review and motivation}\n\n\\hskip 15pt Along with the phenomenal growth in the overall tourism flows in the world over the past two decades the interest in research for tourism is growing rapidly also. Being one of the important areas in tourism research, tourism demand (or tourism flows) modelling and forecasting has attracted much attention of both academics and practitioners. According to Song and Li `r Cite(bib, 'Studies1', .opts = list(cite.style = \"numeric\"))` in the articles published from 2000 to 2007 regarding tourism flows out of 121 studies regarding econometric modelling 72 times time-series methods were used. This means that the authors most often use the lags of the tourism flows to help in explaining the tourism demand. The dominant choices were ARIMA, SARIMA, VAR and neural network models. For example, Otieno, Munguatu and and Orwa `r Cite(bib, 'SARIMA', .opts = list(cite.style = \"numeric\"))` analyzed tourism accommodation demand in Kenya from the year 1974 to 2011 and found that the best model that fits the demand is SARIMA (1,1,2)(1,1,1)[4] model and it showed the best results when forecasting the future toursim flows.  But in order to only rely on the time series itself in order to build a model one must have quite a substantial amount of data points and the frequency of the data must be at least quarterly (to help identify the seasonality, etc.). Additionally, time series modelling methods rely on the assumption that the data is stationary or can be made stationary with differentiation. But the real world data is often quite complex and chaotic thus making it difficult for typical time series methods to give proper results.\n\n\\hskip 15pt According to Song and Li \"panel data analysis has some advantages over the time series econometric models. It incorporates much richer information from both time-series and cross-sectional data\". Furthermore, when working with data with a low number of time periods (as is often the case with annual data) but having a relatively big number of respondents (typically countries) the advantages of using structural or panel models are evident. Altough in the study which was conducted by Song and Li only 4 articles out of 121 featured panel models. This can be explained by the fact that there is a lack of theoretical foundations into how economic growth (and all of associated variables) influence the tourism flows (and vice versa) `r Cite(bib, 'Studies2', .opts = list(cite.style = \"numeric\"))`. \n\n\\hskip 15pt Putting asside the economic theory behind the factors of tourism flows the usage of panel models in trying to explain tourism demand is growing. According to Seetaram and Petit this is because from the later half of the past decade in addition to static fixed and random effects models, the dynamic panel models have given meaningful results. Cortez Jimenez `r Cite(bib, 'example1', .opts = list(cite.style = \"numeric\"))` analyzed the impact of tourism to economic growth of Spain (using GDP per capita as a proxy variable) and found that tourism flows has a significant impact to the long-term economic growth of the mediterranean region of Spain while the inland region suffered a negative impact from tourism flows. \n\n\\hskip 15pt Another example of the implementation of the panel models is a study by Soukiazis and Proancea (2008) whom conducted an analysis of tourism and economic growth relationship in Portugal's regions and concluded that a 0.01 percent increase in GDP per capita would lead to an increase of about 1 percent of total bed capacity (hotel accommodations) in the surveyed regions. \n\n\\hskip 15pt The dissadvantages of the panel data analysis comes from the data itself. As is noted by Kitamura `r Cite(bib, 'example1', .opts = list(cite.style = \"numeric\"), after=\" , pp. 127\")`  \n\n\\hskip 15pt $\\bullet$ Respondents may find it cumbersome to regularly participate in the same survey, which results in increasing non-response.\n\n\\hskip 15pt $\\bullet$ Attrition or dropout rate from the sample can be high.\n\n\\hskip 15pt $\\bullet$ Overtime the accuracy of data collection may decline. This is known as ‘panel\nfatigue’.\n\n\\hskip 15pt $\\bullet$ The response of individuals may be influence by their responses from previous\nparticipations. \n\n\\hskip 15pt This is indeed an issue when working with micro data - surveys, data collected from small provinces or regions and so forth. But data which is gathered by big organizations like the World Bank, OECD or the statistics departments of the countries which were mentioned in the introduction does not suffer from this problem. Altough another downfall is that in the latter case the data may be too much aggregated. \n\n\\hskip 15pt Given that the macro annual data which is publicly available does not feature the disadvantages from Kitamura's list and that in order to construct a panel model one does not need high frequency data we have chosen the panel models in order to help determine the biggest factors to tourism flows in the Western world. Additionally this thesis emphasizes the need to determine the relationship between the tourism flows and economic variables and not to forecast it thus we favour panel models over the time series ones.\n\n\\hskip 15pt For this paper only public and free data is used which is strongly aggregated. This could mask some significant variables. It is strongly believed that using not public data that has a very thorough structure of the tourist arrivals the task of finding influential variables to toursim flows would be more straightforward. Nonetheless, the data from the OECD and World Bank's databases have annual cross-sectional data for the countries mentioned above which enables us to use various econometric tools in order to find significant variables to help explain the tourism flows.  \n\n\\newpage\n\n\\section{Economic variable selection}\n\n\\hskip 15pt The increase in tourism is evident in the countries which are analyzed. This can be seen in the overall sum of arrivals in every year.\n\n```{r arrival trend, echo=F, fig.cap=\"Trend of tourists arrivals\", fig.height=6, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n\ndt.a <- master.data[, c(\"Country\", \"Date\", \"Total.Arrivals\"), ]\n\ndt.a <- ddply(dt.a, ~Date, function(xframe){\n  \n  xframe <<- xframe\n  \n  results <- data.frame(Country='All', Date=xframe$Date[1], Total.Arrivals=sum(xframe$Total.Arrivals, na.rm=T))\n  xframe <- rbind(xframe, results)\n  return(xframe[nrow(xframe), ])\n\n})\n\ndt.a$Total.Arrivals <- dt.a$Total.Arrivals/1000\ndt.a$Date <- as.numeric(dt.a$Date)\n\np <- ggplot(dt.a, aes(x=Date, y=Total.Arrivals, group=Country, colour=Country, label=Country)) + geom_line(size=1.2) + ylab(\"Total Arrivals, thousands\") + theme_bw() + scale_x_continuous(expand = c(0, 4)) + geom_dl(aes(label = Country), method = list(dl.combine(\"first.polygons\"), cex = 1)) + geom_dl(aes(label = Country), method = list(dl.combine(\"last.polygons\"), cex = 1)) + stat_smooth(se = FALSE, method = \"lm\", formula = y ~ ns(x,1),aes( colour=\"Linear trend\"), linetype=\"dashed\")  + scale_colour_manual(values = c(\"coral3\", \"darkblue\"),\n                       guide = guide_legend(override.aes = list(\n                         linetype = c(\"solid\", \"dashed\"),\n                         shape = c(16, 16)), title=\"Legend\"))\n\nplot(p)\n\n```\n\n\\hskip 15pt From figure 1 we can clearly see that the overal sum of tourist arrivals through the years is increasing rapidly. \n\n\\hskip 15pt The aim of this paper is to create a model to help explain the total number of arrivals of tourists to a given country which was mentioned in the introduction. There are several factors influencing the tourism market in general `r Cite(bib=bib, 'factors', .opts = list(cite.style = \"numeric\"))`:\n\n\\hskip 15pt $\\bullet$ Environmental factors \n\n\\hskip 15pt $\\bullet$ Historical and cultural factors\n\n\\hskip 15pt $\\bullet$ Socio-economic factors \n\n\\hskip 15pt $\\bullet$ Religious factors \n\n\\hskip 15pt $\\bullet$ Other factors \n\n\\hskip 15pt This paper focuses more on the socio-economic variables, because they in general can be expressed in numbers and are not constant over time. \n\n\\hskip 15pt Accessibility is an important socio-economic variable. All tourist centers must be easily accessible by various modes of transportation like roads, railways, air and water. To reflect accessibility the investments to inroad infrastructure ($Investment$) variable is used.\n\n\\hskip 15pt Another factor influencing tourism are the various attraction sites in a given country: ranging from big ones like amusement parks, natural wonder sites to the small ones like coffehouses, restaurants. All of these businesses have to be maintained and a big factor are the taxes on these services. As a reflection of how governments help or not in increasing the tourism flows to these businesses  the taxes on goods and services ($tax$) variable is used. Also, the overall economic state of a country has a strong correlation with the amount of new shops, hotels and other attractions that can be opened in a given country. As a proxy for the overall state of a country GDP per capita ($GDP$) variable is used. Also, a better economic state of a country means that there are more ancillary services: banking and finance, internet and telecom connectivity, hospitals, insurance and so on. Adding to the socio-economic variables it can be argued that more hours worked in a country positively influence the number of services that could be provided for the tourists. To measure this we will use the annual average hours worked variable ($hours worked$).  \n\n\\hskip 15pt Additional variable that may influence tourism in the Western countries is terrorism. At least in the Islamic countries, in the country where the attack took place, one additional fatal incident is predicted to reduce the tourist flow from the country of the main victims by 4.2 per cent in the same year and by 7.4 per cent in the subsequent one `r Cite(bib=bib, 'terror.absolute', .opts = list(cite.style = \"numeric\"))`.\n\n\\hskip 15pt There is also the so called spill-over effect:\n\n\\hskip 15pt If tourists from a certain country, Germany for example, have become victims of fatal terrorist incidents in an Islamic country, such as Tunisia for example, this also affects tourism from Germany to other Islamic countries, such as Egypt. Thus one incident involving nationals from Germany has a significant negative effect to the tourism flows to all of the Islamic countries `r Cite(bib=bib, 'terror.absolute', .opts = list(cite.style = \"numeric\"))`.  \n\n\\newpage\n\n\\hskip 15pt Taking into account all of this information our aim is to find the function \\textbf{f} in the equation:\n\n\\[\nlog(A)_{it}  = \\textbf{f}(\\Delta log(GDP)_{it}, \\Delta terror_{it}, \\Delta log(hours)_{it}, \\Delta tax_{it}, \\Delta Investment)\n\\]\n\nWhere\n\n$A_{it}$ - total number of arrivals to a country i at time period t, thousands\n\n$GDP_{it}$ - GDP per capita at a country i at time period t, thousands \n\n$terror_{it}$ - total number of terrorist attacks at country i at time period t\n\n$hours_{it}$ - average numbers of hours worked annualy in country i at time period t\n\n$tax_{it}$ - percentage of taxes on goods and services.\n\n$Investment_{it}$ - investment to inland infrastructure, percent of GDP.\n\n<!-- \\subsection{Motivation behind variable selection} -->\n\n\\hskip 15pt All of these variables are available for France, United Kingdom, USA, Canada, Germany, Spain, Portugal, Netherlands, Austria, Italy and Belgium from the year 1996 to 2014. Note that we will be using cross-sectional panel data for each of the countries. This equals to 209 observations.\n\n\\newpage\n\n\\subsection{Variable analysis}\n\n\\hskip 15pt The variable $GDP$ is chosen to reflect the economic situation and the standart of living in a given country. GDP per capita is calculated by taking the total output of a country and dividing it by the number of people in the country. The division by the number of people helps us to compare economies between countries. \n\n```{r OECD GDP per capita, echo=F, fig.cap=\"GDP per capita of OECD\", fig.height=6, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n\ndt.a <- master.data[, c(\"Country\", \"Date\", \"gdp\")]\n\ndt.a <- ddply(dt.a, ~Date, function(xframe){\n  \n  xframe <<- xframe\n  \n  results <- data.frame(Country='All', Date=xframe$Date[1], gdp=mean(xframe$gdp, na.rm=T))\n  xframe <- rbind(xframe, results)\n  return(xframe[nrow(xframe), ])\n\n})\n\ndt.a <- rename(dt.a, c(\"gdp\" = \"value\"))\ndt.a$Date <- as.numeric(dt.a$Date)\n\np <- ggplot(dt.a, aes(x=Date, y=value, group=Country, colour=Country, label=Country)) + geom_line(size=1.2) + ylab(\"GDP per capita, USD\") + theme_bw() + scale_x_continuous(expand = c(0, 4)) + geom_dl(aes(label = Country), method = list(dl.combine(\"first.polygons\"), cex = 1)) + geom_dl(aes(label = Country), method = list(dl.combine(\"last.polygons\"), cex = 1))  + stat_smooth(se = FALSE, method = \"lm\", formula = y ~ x,aes( colour=\"Linear trend\"), linetype=\"dashed\") +\nscale_colour_manual(values = c(\"darkblue\", \"coral3\"),\n                       guide = guide_legend(override.aes = list(\n                         linetype = c(\"dashed\", \"solid\"),\n                         shape = c(16, 16)), title=\"Legend\")) \n\nplot(p)\n\n```\n\n\n\\hskip 15pt Ever since Simon Kuznets presented the idea of GDP (or rather GNP (gross national product) back in those days) to US congress in 1934 `r Cite(bib=bib, 'GDP', .opts = list(cite.style = \"numeric\"), after=\" ,see pp. 6\")` this number has been the dominant measure of economic growth. Altough it was invented to better gauge the economy of the USA in the Great Depression and help the government to implement the right policies, GDP as a measure has spreaded to almost all of the world as a basis for governments to keep track of the economies. GDP is defined by the following formula for country $i$ at time period $t$:\n\n$$GDP_{it} = consumption_{it} + investment_{it} + government spending_{it} + exports_{it} - imports_{it}$$\n\n```{r bvp vs tourist arrivals, echo=F, warning=F ,fig.cap=\"The colours on the graph on the left simbolize a different country.\", fig.height=6, fig.width=10,  fig.pos=\"!ht\", fig.align=\"center\"}\n\npar(mfrow=c(1, 2))\n\ngrid.frame(x=pdata$gdp, y=pdata$Total.Arrivals, xlab=\"GDP per capita\", ylab=\"Total arrivals\")\n\nfor(cn in unique(pdata$Country)){\n  matplot(x=pdata[pdata$Country==cn, \"gdp\"], y=pdata[pdata$Country==cn, \"Total.Arrivals\"], type=\"p\", pch=19, add=T, col=which(cn==unique(pdata$Country)))\n}\n\n matplot(x=pdata$gdp, y=pdata$Total.Arrivals, type=\"p\", pch=19, xlab=\"GDP per capita\", ylab=\"Total arrivals\", col=\"dodgerblue1\")\n grid()\n \n```\n\n\\hskip 15pt As we can see from figure 3, visually there is no clear relationship between changes in GDP per capita and total number of tourist arrivals. In order to see a more clear picture we need to plot not all of the countries but some of them. Because of the panel structure of our data some visual trends might be lost because of the abundance of points. \n\n```{r bvp vs tourist arrivals selected countries, echo=F, warning=F ,fig.cap=\"Percentage change in GDP vs percentage change in total arrivals\", fig.height=8, fig.width=9,  fig.pos=\"!ht\", fig.align=\"center\"}\n\n par(mfrow=c(2, 2))\n\nfor(cn in unique(pdata$Country)[1:4]){\n  \n  grid.frame(x=pdata$gdp, y=pdata$Total.Arrivals, xlab=\"GDP per capita\", ylab=\"Total arrivals\")\n  matplot(x=pdata[pdata$Country==cn, \"gdp\"], y=pdata[pdata$Country==cn, \"Total.Arrivals\"], type=\"p\", pch=19, add=T, col=\"blue\")\n  model <- lm(Total.Arrivals ~ gdp, data=pdata[pdata$Country==cn, ])\n  abline(model, col=\"red\")\n  info <- summary(model)$coefficients\n  p.val <- info[, \"Pr(>|t|)\"][2]\n  legendary2(\"Regression line\", col=\"red\")\n  mtext(cn, adj=0, line=2, cex=1.2, col=\"dodgerblue1\")\n  mtext(paste(\"p - value for regressor:\", round(as.numeric(p.val), 3)), line=1, adj=0, col=\"salmon1\")\n  \n}\n\n \n```\n\n\\hskip 15pt Figure 4 gives a more clear picture. Percentage changes in GDP per capita is significant for Austria from the 4 countries that are visualized. Panel models will help to tell that if GDP per capita is a significant variable for the whole group of countries and not for certain ones.   \n\n\\hskip 15pt All of the scatterplots for GDP and the variables mentioned at the start of the section are added to the $\\textbf{appendix 3}$.\n\n\\newpage\n\n\\section{Modelling}\n\n\\subsection{Panel data structure}\n\n\\hskip 15pt Panel data provides information on individual behaviour, both across individuals and over time - the data has cross-sectional and time-series dimensions. Panel data includes N individuals over T regular time periods. We can denote a panel data model similarly like a typical bivariate reggression model `r Cite(bib, 'econometric.methods', .opts = list(cite.style = \"numeric\"), after=\" , pp. 390\")`:\n\n\\[\n\\tag{1}\n  y_{it} = \\alpha_{i} +  X_{it} \\beta + u_{it}\n\\]\n\n\\hskip 15pt The difference from a typical reggression model is that there are the $i$ and the $t$ terms, where $i$ denotes the individual and $t$ denotes the time period. The construction of a panel model starts with appropriately 'stacking' the data set. Assuming that y is the dependant variable and X is the matrix of the explanatory variables we need to have the following structure  `r Cite(bib, 'econometric.methods', .opts = list(cite.style = \"numeric\"), after=\" , pp. 388\")`: \n\n\\[\n  Y = y_{i} = \\begin{bmatrix}\n         y_{1}    \\\\\n         y_{2}    \\\\[0.3em]\n         \\vdots   \\\\[0.3em]\n         y_{N}     \n  \\end{bmatrix} = \\begin{bmatrix}\n         e    \\\\\n         0    \\\\[0.3em]\n         \\vdots   \\\\[0.3em]\n         0     \n  \\end{bmatrix}  \\alpha_{1} + \\begin{bmatrix}\n       0    \\\\\n       e    \\\\[0.3em]\n       \\vdots   \\\\[0.3em]\n       0    \n\\end{bmatrix}  \\alpha_{2} + \\cdots + \\begin{bmatrix}\n       0    \\\\\n       0    \\\\[0.3em]\n       \\vdots   \\\\[0.3em]\n       e     \\\\[0.3em]\n\\end{bmatrix}  \\alpha_{N} + \\begin{bmatrix}\n       x_{1}    \\\\[0.3em]\n       x_{2}    \\\\[0.3em]\n       \\vdots   \\\\[0.3em]\n       x_{n}     \\\\[0.3em]\n\\end{bmatrix} \\beta +   \\begin{bmatrix}\n       u_{1}    \\\\[0.3em]\n       u_{2}    \\\\[0.3em]\n       \\vdots   \\\\[0.3em]\n       u_{n}     \\\\[0.3em]\n\\end{bmatrix}\n\\]\n\nWhere\n\n\\[\ny_{i} = \\begin{bmatrix}\n       y_{i1}    \\\\\n       y_{i2}    \\\\[0.3em]\n       \\vdots   \\\\[0.3em]\n       y_{iT}     \\\\[0.3em]\n\\end{bmatrix} x_{i} = \\begin{bmatrix}\n       x_{1i1} & x_{2i1} & \\cdots & x_{Ki1}    \\\\\n       x_{1i2} & x_{2i2} & \\cdots & x_{Ki2}   \\\\[0.3em]\n       \\vdots & \\vdots & \\cdots & \\vdots   \\\\[0.3em]\n      x_{1iT} & x_{2iT} & \\cdots & x_{KiT}      \\\\[0.3em]\n\\end{bmatrix}\n\\]\n\n\\hskip 15pt For example, the 'head' of the raw data which is analysed looks like this:\n\n```{r visualising data table, echo=F}\n\nkable(head(pdata), format = \"latex\", row.names = F)\n# kable(tail(pdata), format = \"latex\", row.names = F)\n\n```\n\n\\newpage\n\n\\subsection{Unit roots}\n\n\\hskip 15pt Before modelling we need to check whether there are unit roots in our data set. We do this because the presence of a unit root can dramatically effect the asymptotic properties of the coefficients gotten from panel models. Also the test results for variable significance may be misleading `r Cite(bib, 'Unit.roots', .opts = list(cite.style = \"numeric\"), after=\" , pp. 3\")`. We use the \\textit{purtest()} function to check for this. This function implements the Maddala and Wu test.\n\n```{r adf data, echo=F, warning=F, comment=NA}\n\nArrivals <- as.data.frame(split(pdata$Total.Arrivals, pdata$Country))\n\nGDP <- as.data.frame(split(pdata$gdp, pdata$Country))\n\nHours <- as.data.frame(split(pdata$hours.worked, pdata$Country))\n\nAttacks <- as.data.frame(split(pdata$Terror.attacks, pdata$Country))\n\nTax <- as.data.frame(split(pdata$tax, pdata$Country))\n\nInve <- as.data.frame(split(pdata$Investment, pdata$Country))\n```\n\n\n```{r adf, echo=F, warning=F, comment=NA}\n\nresult.table <- matrix(ncol=2, nrow=6) %>% as.data.frame()\nnames(result.table) <- c(\"Variable\", \"p-value\")\nresult.table$Variable <- c(\"Arrivals\", \"GDP\", \"Hours\", \"Attacks\", \"Tax\", \"Investment\")\n\nt <- purtest(Arrivals, pmax = 4, exo = \"intercept\", test = \"madwu\")\n\nresult.table[1, \"p-value\"] <- t$statistic$p.value\n\nt <- purtest(GDP, pmax = 4, exo = \"intercept\", test = \"madwu\")\n\nresult.table[2, \"p-value\"] <- t$statistic$p.value\n\nt <- purtest(Hours, pmax = 4, exo = \"intercept\", test = \"madwu\")\n\nresult.table[3, \"p-value\"] <- t$statistic$p.value\n\nt <- purtest(Attacks, pmax = 4, exo = \"intercept\", test = \"madwu\")\n\nresult.table[4, \"p-value\"] <- t$statistic$p.value\n\nt <- purtest(Tax, pmax = 4, exo = \"intercept\", test = \"madwu\")\n\nresult.table[5, \"p-value\"] <- t$statistic$p.value\n\nt <- purtest(Inve, pmax = 4, exo = \"intercept\", test = \"madwu\")\n\nresult.table[6, \"p-value\"] <- t$statistic$p.value\n\n\n```\n\n\\begin{center}\n\n```{r visualising data table 2, echo=F}\n\nkable(result.table, format = \"latex\", row.names = F, digits = 5)\n\n```\n\n\\end{center}\n\n\\hskip 15pt The alternative hypothesis for the test is that the data does not have a unit root. All values in the table are much lower than 0.05. According to the tests no variable has a unit root. This is highly expected because all of the variables are differenced which is a standart procedure to insure the elimination of the unit roots from the data. \n\n\\newpage\n\n\\subsection{Pooling estimator}\n\n\\hskip 15pt The first model which is examinied is the simple OLS model which ignores the panel data structure. The equation is then:\n\n\\[\ny = \\alpha + X \\beta + \\epsilon\n\\]\n\n\\hskip 15pt And the estimator is derived solving the equation:\n\n\\[\n\\widehat{\\beta} = \\left( X X^{T} \\right)^{-1}X^{T}y\n\\]\n\n```{r pooling panel model, include=FALSE, echo=F, warning=F}\n\nmodel.ols <- lm(formula = Total.Arrivals ~ Terror.attacks + hours.worked + tax + gdp + Investment, data=pdata)\n# pdata <- pdata[-which(cooks.distance(model.ols)>(4/length(cooks.distance(model.ols)))), ]\n# summary(model.ols)\n```\n\n```{r xtable, results=\"asis\", echo=F, warning=F}\ntab <- xtable(summary(model.ols)$coef, digits=c(3, 3, 3, 3, 3), caption = \"OLS model\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n```\n\n\\hskip 15pt We can use this model to inspect the residuals and remove some outliers from our data set. The residuals can be inspected in figure 5. We will remove all the points that are above the blue line in the cook's distance plot.\n\n```{r cooks distance initiale, echo=F, fig.cap=\"Residuals\", fig.height=7, fig.width=7,  fig.pos=\"h\"}\n\npar(mfrow=c(2, 1))  \nplot(model.ols, 4, col=\"salmon1\", lwd=2)\nabline(h=4/length(model.ols$residuals), col=\"dodgerblue1\", lwd=2)\nlegendary2(col=\"dodgerblue1\", \"4/number of obs.\")\ngrid()\n\nc.dist <- cooks.distance(model.ols)\nr <- stdres(model.ols)\nplot(r, type=\"l\", xlab=\"number of obs.\", ylab=\"Residaul\", main=\"Plot of standartized residuals\", col=\"salmon1\")\nabline(h=3*sd(r), col=\"dodgerblue1\", lwd=2)\nabline(h=-3*sd(r), col=\"dodgerblue1\", lwd=2)\nlegendary2(col=\"dodgerblue1\", \"3 sigmas\")\ngrid()\n\npdata <- pdata[-which(cooks.distance(model.ols)>(4/length(cooks.distance(model.ols)))), ]\n```\n\n```{r pooling panel model without outliers, include=FALSE, echo=F, warning=F}\n\nmodel.ols <- lm(formula = Total.Arrivals ~  hours.worked + tax, data=pdata)\n# pdata <- pdata[-which(cooks.distance(model.ols)>(4/length(cooks.distance(model.ols)))), ]\n# summary(model.ols)\n```\n\n```{r xtable 2, results=\"asis\", echo=F, warning=F}\ntab <- xtable(summary(model.ols)$coef, digits=c(3, 3, 3, 3, 3), caption = \"OLS model without outliers\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n```\n\n\\hskip 15pt Table 2 represents the final linear model without the outliers and the insignificant variables. \n\n\\newpage\n\n\\subsection{Fixed effects model}\n\n\\hskip 15pt In this section a fixed effects panel data model  `r Cite(bib, 'econometric.methods', .opts = list(cite.style = \"numeric\"), after=\" , pp. 395 - 399\")` is created. Recall equation (1). The $\\alpha_{i}$ is called the \\textit{individual effect}.\nIf $\\alpha_{i}$ does correlate with $X_{it}$ then the panel model can be reffered to as a fixed effects model. \n\n\\subsubsection{Model assumptions}\n\n\\hskip 15pt Let as assume that we have n individuals and T observations for each individual. The fixed effects model has the following structure:\n\n$$y_{it} = X_{it} \\beta + \\epsilon_{it} $$\n$$\\epsilon_{it} = \\alpha_{i} + \\eta_{it} $$\n\nThe assumptions for the errors are:\n\n$$\\mathbf{E}[\\eta | \\mathbf{X}] = 0 ; E[\\eta\\eta^{\\prime} | \\mathbf{X}] = \\sigma^{2}_{\\eta}I_{nT}$$\n\n$$\\mathbf{E}[\\alpha_{i}\\alpha_{j} | \\mathbf{X}] = 0, \\forall i\\neq j;  E[\\alpha\\alpha^{\\prime} | \\mathbf{X}] = \\sigma^{2}_{\\alpha}$$\n\n$$\\mathbf{E}[\\alpha_{i}\\eta_{j} | \\mathbf{X}] = 0, ;  E[\\alpha | \\mathbf{X}] = 0$$\n\n\\hskip 15pt In the fixed effects model case the $\\alpha_{i}$ term is treated as an unknown parameter and has to be estimated. \n\n\\subsubsection{Obtaining estimates}\n\n\\hskip 15pt To obtain the $\\widehat{\\beta_{FE}}$ we first \"demean\" the data. $\\forall i$:\n\n$$y_{it} - \\overline{y_{i}} = \\left(X_{it} -  \\overline{X_{i}}\\right) \\beta + \\left( \\alpha_{i}  - \\overline{\\alpha_{i}}\\right) + \\left( \\epsilon_{i}  - \\overline{\\epsilon_{i}}\\right)$$\n\n\\hskip 15pt Now since $\\overline{\\alpha_{i}}$ is just $\\alpha_{i}$ then the above equations simplifies to:\n\n$$\\dot{y} := y_{it} - \\overline{y_{i}} = \\left(X_{it} -  \\overline{X_{i}}\\right) \\beta + \\left( \\epsilon_{i}  - \\overline{\\epsilon_{i}}\\right) =: \\dot{X} \\beta_{FE} + \\dot{\\epsilon}$$\n\n\\hskip 15pt To obtain the estimate $\\widehat{\\beta_{FE}}$ we simply run an OLS procedure to the equation above. The estimator $\\widehat{\\beta_{FE}}$ is often called the within estimator. Any procedure that eliminates the term $\\alpha_{i}$ can be called a $\\textit{within transformation}$. To obtain the $\\alpha_{i}$ for every $i$ we simply match the intercept coordinates that is estimated by running the reggresion for the demeaned data with the way the data was stacked. \n\n\\newpage\n\n\\subsubsection{Results}\n\n```{r fixed effects model, include=FALSE, echo=F}\n\nmodel.fixed <- plm(formula = Total.Arrivals ~ Terror.attacks + hours.worked + tax + gdp + Investment, data=pdata, model=\"within\")\n# summary(model.fixed)\n```\n\n```{r, results='asis', echo=F, warning=F}\n\ntab <- xtable(summary(model.fixed)$coef, digits=c(3, 3, 3, 3, 3), caption = \"Fixed effects model\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\n\\hskip 15pt As we can see from table 3 the coefficients have a simmilar signs to them as in the OLS case. The significant variables are the average hours worked and taxes. \n\n\\hskip 15pt After dropping the insignificant variables we have:\n\n\n```{r final models, include=FALSE, echo=F}\n\nmodel.fixed <- plm(formula = Total.Arrivals ~ Terror.attacks + hours.worked + tax, data=pdata, model=\"within\")\nols.model <- lm(formula = Total.Arrivals ~ Terror.attacks + hours.worked + tax, data=pdata)\n```\n\n```{r, results='asis', echo=F, warning=F}\n\ntab <- xtable(summary(model.fixed)$coef, digits=c(4, 4, 4, 4, 4), caption = \"Final fixed effects model\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\n\\hskip 15pt The final panel fixed effects model is presented in table 4. We will leave the variable regarding terror attacks altough it has a high p value (>0.1) because it is much lower than in the typical OLS case (table 1). According to this model, one additional terror attack would lead to a decrease of tourist arrivals by 0.02 percent. A one percent increase to annual hours worked would lead to a 1.02 percent increase of tourist arrivals and one percent increase to taxes on goods and services would lead to a decrease of about 0.9 percent of the tourists. \n\n```{r estimating ols and fixed model fits, echo=F, comment=NA}\n  \n  pdata <- ddply(pdata, ~Country + Date, function(xframe){\n    \n    xframe <<- xframe\n    \n    \n    ## fixed effects\n    \n    intercept <- fixef(model.fixed)[xframe$Country[1]] %>% as.numeric()\n    X <- xframe[, c('Terror.attacks', 'hours.worked', \"tax\")]\n    fit <- model.fixed$coefficients[1] * X[1] +  model.fixed$coefficients[2] * X[2] +  model.fixed$coefficients[3] * X[3] + intercept\n    fit <- as.numeric(fit) # this is the fit of the logged number of arrivals\n    xframe$fc.fixed.effect <- fit\n    \n    ## OLS\n    \n    X <- xframe[, c('hours.worked', \"tax\")] \n    fit <- model.ols$coefficients[2] * X[1] + model.ols$coefficients[3] * X[2]\n    fit <- fit + model.ols$coefficients[1] \n    xframe$fc.OLS <- as.numeric(fit)\n    \n    return(xframe)\n  })\n\n```\n\n\\newpage\n\n\n<!-- # ```{r visualizing the differences between fits, echo=F, fig.cap=\"OLS and fixed effects model comparison\", fig.height=6, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"} -->\n<!-- #    -->\n<!-- # fdt <- pdata[, c(\"Country\", \"Date\", \"Total.Arrivals\", \"fc.fixed.effect\", 'fc.OLS')] -->\n<!-- # # fdt$Total.Arrivals  <- exp(fdt$Total.Arrivals)/1000 -->\n<!-- # # fdt$fc.fixed.effect <- exp(fdt$fc.fixed.effect)/1000 -->\n<!-- # # fdt$fc.OLS          <- exp(fdt$fc.OLS)/1000 -->\n<!-- # fdt$Date <- fdt$Date %>% as.character() %>% as.numeric() -->\n<!-- #  -->\n<!-- # ## we will plot 4 countries in order to have a clear picture -->\n<!-- # cn <- c( \"United States\",  \"Austria\", \"France\", \"Spain\") -->\n<!-- # points <- data.frame() -->\n<!-- #  -->\n<!-- # par(mfrow=c(2,2)) -->\n<!-- # for(cc in cn){ -->\n<!-- #    -->\n<!-- #   tmp <- fdt[fdt$Country==cc, ] -->\n<!-- #   points <- tmp[, c(\"Total.Arrivals\", \"fc.fixed.effect\", 'fc.OLS')] -->\n<!-- #    -->\n<!-- # grid.frame(x=as.numeric(tmp$Date), y=points) -->\n<!-- #   matplot(x=as.numeric(tmp$Date), y=points, lwd=1, lty=1, cex=1.25, pch=20, xlab=\"Time\", ylab=\"Arrivals, thousands\", add = T, type=\"o\", -->\n<!-- #         col=c('salmon1', \"firebrick1\", 'cornflowerblue')) -->\n<!-- #   legendary2(c(\"Original\", \"Fixed effect fit\", \"OLS fit\"), col=c('salmon1', \"firebrick1\", 'cornflowerblue')) -->\n<!-- #   mtext(cc, col=\"blueviolet\", line=2, cex=1.25, adj = 0) -->\n<!-- # } -->\n<!-- #  -->\n<!-- # ``` -->\n\n\\newpage\n\n\\subsection{Random effects model}\n\n\\hskip 15pt There are two main types of panel models: the fixed effects model and the random effects models `r Cite(bib, 'econometric.methods', .opts = list(cite.style = \"numeric\"), after=\" , pp. 391 - 393\")`. The main difference between them is the assumption of $\\alpha_{i}$ regarding the regressor matrix $X_{it}$. In the random effects model case it is assumed that $\\alpha_{i}$ and $X_{it}$ do not correlate.\n\n```{r random effects model, include=FALSE, echo=F}\n\nmodel.random <- plm(formula = Total.Arrivals ~ Terror.attacks + gdp + tax + hours.worked + Investment, data=pdata, model=\"random\")\n# summary(model.random)\n```\n```{r, results='asis', echo=F, warning=F}\n  # texreg(model.random, caption = \"Random effects model\", custom.coef.names = c(\"intercept\", \"attacks\", \"log GDP\", \"log Hours\"), digits = 3)\n\ntab <- xtable(summary(model.random)$coef, digits=c(3, 3, 3, 3, 3), caption = \"Random effects model\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n```\n\n\\hskip 15pt Comparing tables 3 and 5 we can see that the signs near the coefficients are the same and the actual values of the estimators are almost even. The main difference here is that there is the intercept term and we lose some \"uniqueness\" to the countries which was present with the fixed effects model. One measure to determine which model is better for the given data is the Hausman test. Just like in the previous cases, the only significant variable is the hours worked variable. The final random effects model:\n\n\n```{r random effects model 2, include=FALSE, echo=F}\n\nmodel.random <- plm(formula = Total.Arrivals ~ tax + hours.worked, data=pdata, model=\"random\")\n\n```\n```{r, results='asis', echo=F, warning=F}\n\ntab <- xtable(summary(model.random)$coef, digits=c(3, 3, 3, 3, 3), caption = \"Random effects model\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n```\n\n\\hskip 15pt The Hausman test's (the test is explained more in depth in $\\textbf{appendix 1}$) p value is equal to 0.29 which implies that we cannot reject the null hypothesis therefore we conclude that the random effects coefficients are more efficient and are consistent. Therefore the test implies that we sould use the random effects model.\n\n```{r estimating random model fits, echo=F, comment=NA}\n  \n  pdata <- ddply(pdata, ~Country + Date, function(xframe){\n    \n    xframe <<- xframe\n    \n    ## random effects\n\n    X <- xframe[, c('hours.worked', \"tax\")]\n    fit <- model.random$coefficients[1] + model.random$coefficients[2] * X[2] +  model.random$coefficients[3] * X[1]\n    fit <- as.numeric(fit) # this is the fit of the logged number of arrivals\n    xframe$fc.random.effect <- fit\n    \n    return(xframe)\n  })\n\n```\n\n\\newpage\n\n\n\\subsection{Statistics for accuracy}\n\n\\hskip 15pt We can measure the goodness of fit using several statistics. We will use the the \\textit{mean absolute error} (MAE), \\textit{mean squared error} (MSE)\nand the \\textit{mean absolute percentage error} (MAPE)  `r Cite(bib, 'accuracy', .opts = list(cite.style = \"numeric\"))`. These statistics are defined by:\n\n\\[\nMSE = \\dfrac{1}{n}  \\sum_{i=1}^{n}\\left( y - \\widehat{y} \\right)^{2}\n\\]\n\n\\[\nMAE = \\dfrac{1}{n}  \\sum_{i=1}^{n}\\left| y - \\widehat{y} \\right|\n\\]\n\n\\[\nMAPE = \\dfrac{100}{n}  \\sum_{i=1}^{n}\\left| \\dfrac{y - \\widehat{y}}{y} \\right| \n\\]\n\nWhere\n\n$\\widehat{y}$ - fitted value\n\n$y$ - original value\n\n\n$n$ - number of observations\n\n\n\\begin{center}\n\n```{r forecast accuracy, echo=F, results= \"asis\", fig.pos=\"H\"}\n  \nfdt <- pdata[, c(\"Country\", \"Date\", \"Total.Arrivals\", \"fc.fixed.effect\", 'fc.OLS', \"fc.random.effect\")]\n# fdt$Total.Arrivals  <- exp(fdt$Total.Arrivals)\n# fdt$fc.fixed.effect <- exp(fdt$fc.fixed.effect)\n# fdt$fc.OLS          <- exp(fdt$fc.OLS)\n\naccuracy.table <- matrix(ncol=3, nrow=3) %>% as.data.frame()\ncolnames(accuracy.table) <- c(\"OLS\", \"Fixed effects\", \"Random effects\")\nrownames(accuracy.table) <- c(\"MSE\", \"MAPE\", \"MAE\")\n\n## MSE:\n\naccuracy.table[1, 1] <- MSE(fdt$Total.Arrivals, fdt$fc.OLS)\naccuracy.table[1, 2] <- MSE(fdt$Total.Arrivals, fdt$fc.fixed.effect)\naccuracy.table[1, 3] <- MSE(fdt$Total.Arrivals, fdt$fc.random.effect)\n\n## MAPE\n\naccuracy.table[2, 1] <- MAPE(fdt$Total.Arrivals, fdt$fc.OLS)\naccuracy.table[2, 2] <- MAPE(fdt$Total.Arrivals, fdt$fc.fixed.effect)\naccuracy.table[2, 3] <- MAPE(fdt$Total.Arrivals, fdt$fc.random.effect)\n\n## MAE\n\naccuracy.table[3, 1] <- MAE(fdt$Total.Arrivals, fdt$fc.OLS)\naccuracy.table[3, 2] <- MAE(fdt$Total.Arrivals, fdt$fc.fixed.effect)\naccuracy.table[3, 3] <- MAE(fdt$Total.Arrivals, fdt$fc.random.effect)\n\n# options(\"scipen\" = 5)\n\naccuracy.table <- apply(accuracy.table, c(1, 2), function(x) {\n  # x <- format(x,scientific=FALSE)\n  x <- as.numeric(x)\n  x <- round(x, 3)\n  return(x)\n  })\n\ntab <- xtable(accuracy.table[c(1,3), ], digits=c(3, 3, 3, 3), caption = \"Accuracy statistics results\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n```\n\n\\end{center}\n\n\\hskip 15pt As we can see from table 7 the fixed effects models' predictions are the closest to the original values out of all of the models. Note that we have dropped the MAPE statistic because we are measuring percentage changes and the statistic would give misleading results.\n\n\\newpage\n\n\\subsection{Residuals}\n\n\\hskip 15pt As we saw in the previous section the Hausman test for panel data indicated that we should use the random effects model. The test is only one of the criteria for deciding which model to use. Inspection of the models' residuals is also needed.\n\n```{r residuals of models, echo=F, fig.cap=\"Residuals of models\", fig.height=6, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n  \npar(mfrow=c(1,2))\n\nres.random <- residuals(model.random)\nres.fixed  <- residuals(model.fixed)\n  \ngrid.frame(x=seq(from=1, length.out = length(res.random)), y=as.numeric(res.random))\nmatplot(x=seq(from=1, length.out = length(res.random)), y=as.numeric(res.random), lwd=1, lty=1, cex=1.25, pch=20, ylab=\"Residual value\", xlab=\"Index\", type=\"o\", add=T, col=c('salmon1'))\nmtext(\"Random effects model residuals\", col=\"salmon1\", line=1, cex=1.25, adj = 0)\n\ngrid.frame(x=seq(from=1, length.out = length(res.random)), y=as.numeric(res.random))\nmatplot(x=seq(from=1, length.out = length(res.fixed)), y=as.numeric(res.fixed), lwd=1, lty=1, cex=1.25, pch=20, ylab=\"Residual value\", xlab=\"Index\", type=\"o\", col=c('cornflowerblue'), add=T)\nmtext(\"Fixed effects model residuals\", col=\"cornflowerblue\", line=1, cex=1.25, adj = 0)\n\n```\n\n\\hskip 15pt As we can see in figure 6 the residuals visually look very similar. \n\n```{r distribution of residuals, echo=F, fig.cap=\"Distribution of the residuals\", fig.height=6, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n  \npar(mfrow=c(2,2))\n\nres.random <- residuals(model.random)\nres.fixed  <- residuals(model.fixed)\n  \nhist(res.random, col = \"cornsilk3\", xlab = \"Residuals of the random model\", main=\"Density of the residuals\")\nhist(res.fixed, col = \"cornsilk3\", xlab = \"Residuals of the fixed effects model\", main=\"Density of the residuals\")\n\nqqnorm(res.random, ylab='Residuals', main = \"Q - Q plot for random effects model\", col=\"cornflowerblue\")\ngrid()\nqqline(res.random)\n\nqqnorm(res.fixed, ylab='Residuals', main = \"Q - Q plot for fixed - effects model\", col=\"cornflowerblue\")\ngrid()\nqqline(res.fixed)\n\n```\n\n\\hskip 15pt Figure 7 shows the histogram and the quantile to quantile plot of the residuals. In both cases, the residuals appear to follow a bell - shaped curve which implies normality. Altough the q q plots show that the residuals have heavy tails. This can be expected because real life data very often is not 'clean' enough to give normally distributed errors. \n\n\\newpage\n\n\\subsection{Autocorrelation}\n\n\\hskip 15pt Recall that one of the assumptions for a \"good\" panel model - whether it is fixed or random effects - is that the residuals are not auto-correlated. To test this we can fit an ARIMA (autoregresive integrated moving average) model to the residuals and inspect the results. Additionally we can inspect the auto-correlation functions' (ACF) plot or use the Ljung-Box test (the test is explained more in depth in $\\textbf{appendix 2}$) for autocorrelation in the series.\n\n```{r arima for residuals, echo=F, fig.cap=\"Autocorrelation of the residuals\", fig.height=4, fig.width=7,  fig.pos=\"!ht\", fig.align=\"center\"}\n\npar(mfrow=c(1,2))\n\nres.random <- residuals(model.random)\nres.fixed  <- residuals(model.fixed)\n  \narima.random <- auto.arima(res.random)\narima.fixed  <- auto.arima(res.fixed)\n\nacf(res.random, main=\"Random effects model residuals\")\nacf(res.fixed, main=\"Fixed effects model residuals\")\n\n```\n\n\\hskip 15pt Looking at figure 8 we can see that random effects residuals correlate with the first lag of itself. The $auto.arima ()$ function gives the results that the residuals of the random effects models are an ARIMA (1, 0, 0) process. Finally, the Ljung-Box test's p - value is lower than 0.05 thus meaning that the residuals of the fixed effects model are autocorrelated thus the model does not satisfy the assumptions of the panel models. \n\n\\hskip 15pt The fixed effects' model residuals do not resemble autocorrelation while looking at figure 8. Altough the Ljung-Box test suggests that the residualls are correlated with the 5th lag of itslef. The $auto.arima ()$ function suggests that the residuals are an ARIMA (1, 0, 2) process.\n\n\\hskip 15pt Both the random effects model and fixed effects model are not satisfactory because of the residuals. The failure to meet the fixed effects and random effects theoretical assumptions may give misleading results. Additionally, the random effect models' underlying assumption of $\\alpha_{i}$ not beeing correlated with the explanatory variables is often not true. \n\n\\newpage\n\n\\subsection{General FGLS models}\n\n\\hskip 15pt In order to avoid the autocorrelation in the residuals which causes a negative impact in the model results we may use the robust FGLS (feasible generalized least squares) panel models. General FGLS estimators are based on a two-step estimation process: first an ols model is estimated, then its residuals are used to estimate an error covariance matrix more general than the random effects or the fixed effects one for use in a feasible-gls analysis `r Cite(bib, 'FGLS.info', .opts = list(cite.style = \"numeric\"), after=\" , pp. 25\")`. The function $pggls ()$ implements this procedure in R. In this section we will drop the assumption that $\\alpha_{i}$ does not correlate with $X$ matrix hence we will not analyse random effects models. \n\n```{r pggls models, include=FALSE, echo=F}\n\nmodel.fixed.gg  <- pggls(formula = Total.Arrivals ~ Terror.attacks + gdp + tax + hours.worked + Investment, data=pdata, model=\"within\")\n\n```\n\n```{r, results='asis', echo=F, warning=F}\n\ntab <- xtable(summary(model.fixed.gg)$CoefTable, digits=c(4, 4, 4, 4, 4), caption = \"Fixed effects model (robust)\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\nAfter taking in the consideration the economic logic we get the final robust model:\n\n```{r pggls models final, include=FALSE, echo=F}\n\nmodel.fixed.gg  <- pggls(formula = Total.Arrivals ~ Terror.attacks+ tax + hours.worked, data=pdata, model=\"within\")\n\n```\n\n```{r, results='asis', echo=F, warning=F}\n\ntab <- xtable(summary(model.fixed.gg)$CoefTable, digits=c(4, 4, 4, 4, 4), caption = \"Final fixed effects model (robust)\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\n\\hskip 15pt According to this model, one terrorist attack would lead to a decline of about 0.02 percent of tourist flows. A one percent increase in taxes would lead to a decline of 1.1 percent of tourist arrivals. One percent increase in annual hours worked would increase the tourism flows by about 1.17 percent. The R-squared for the model is 0.14536. As we can see from table's 9 p value collumn the coefficients have changed drastically. This is because the distribution by which the hypothesis for variable significance is tested is different from the one used in the $plm ()$ function and when calculating the standart errors the bias of residual autocorrelation is corrected.\n\n\\hskip 15pt From this section onward panel models are created using the FGLS procedure. \n\n\\newpage\n\n\\subsection{Dynamic panel data model}\n\n\n\\hskip 15pt In this section a dynamic panel model is created:\n\n$$ y_{it} = y_{it - 1} \\delta  +  X_{it} \\beta + \\alpha_{i} + \\epsilon_{it} $$\n\n\\hskip 15pt The creation of a dynamic panel model is not as straightforward as just adding another collumn to the regressor matrix with the lagged variable $y_{it}$. This is because the OLS estimate will be biased. This occurs because of the fact that the $y_{it}$ is a function $\\epsilon_{it}$ and thus so is $y_{it-1}$ giving us the multicolinearity problem. To avoid this we will use a widely accepted Arriano-Bond estimator for dynamic panel models `r Cite(bib, 'dynamic.panel', .opts = list(cite.style = \"numeric\"))`:\n\n$$\\widehat{\\delta} =  \\left[ (\\Delta y_{t - 1})^{t} W (\\widehat{V}_{W})^{-1} W^{t} \\Delta y_{t - 1}\\right]^{-1} x \\left[ (\\Delta y_{t - 1})^{t} W (\\widehat{V}_{W})^{-1} W^{t} \\Delta y_{t - 1}\\right] $$\n\nWhere \n\n$$ \\widehat{V}_{W} = \\sum_{i=1}^{n} W_{i}^{t} \\Delta \\epsilon_{i} \\Delta \\epsilon_{i}^{t}  W_{i}$$\n\n$$W_{i} = \\begin{pmatrix}\n    [y_{i1}, x_{i1}, x_{i2}]       & 0 & \\dots & 0 \\\\\n    0       &  [y_{i1}, y_{i2} x_{i1}, x_{i2}, x_{i3}] & \\dots & 0 \\\\\n    0      & 0  & \\dots & [y_{i1}, y_{i2}, ..., y_{iT-2}, x_{i1}, x_{i2}, x_{i3}, ..., x_{iT-1}]\n\\end{pmatrix} $$\n\n\nThis implementation is done with the plm() `r Cite(bib, 'plm', .opts = list(cite.style = \"numeric\"))` package's function $\\textit{pgmm} ()$ in the statistical package R.\n\n```{r dynamic model, include=FALSE, echo=F}\n\nmodel.dynamic <- suppressWarnings( pgmm(Total.Arrivals ~ Terror.attacks + hours.worked + tax,\n                       lag.form=list(1, 0, 0, 0), gmm.inst = ~ Terror.attacks + hours.worked + tax + gdp + Investment, \n                       lag.gmm = list(c(2,99)),\n                       effect=\"individual\",\n                       data=pdata))\n```\n```{r, results='asis', echo=F, warning=F, fig.pos=\"H\"}\n  # texreg(model.train, caption = \"Fixed effects model with training set\", custom.coef.names = c(\"attacks\", \"log GDP\", \"log Hours\"), digits = 3)\n\ntab <- xtable(summary(model.dynamic)$coef, digits=c(4, 4, 4, 4, 4), caption = \"Dynamic panel data model\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n```\n\n\\hskip 15pt After trying various lags and taking into account the economic logic behind the model we get the results in table 10. The dynamic model shows that terror attacks has a significant influence to tourist arrivals. One additional terror attack would decrease the total number of tourist arrivals by 0.01 percent. The hours worked and the tax variables are also significant with a simillar absolute value as in the fixed effects or the random effects case. An additional significant variable is the lag of the changes in total arrivals. A positive increase in the lags of tourist arrivals will have a positive change to the present change of tourist arrivals. \n\n\\newpage\n\n\\subsection{Dynamic models' residuals}\n\n```{r residuals of dynamic models, echo=F, fig.cap=\"Residuals of models\", fig.height=9, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n  \npar(mfrow=c(3, 1))\n\nres.dynamic <- model.dynamic$residuals %>% unlist\n  \ngrid.frame(x=seq(from=1, length.out = length(res.dynamic)), y=as.numeric(res.dynamic))\nmatplot(x=seq(from=1, length.out = length(res.dynamic)), y=as.numeric(res.dynamic), lwd=1, lty=1, cex=1.25, pch=20, ylab=\"Residual value\", xlab=\"Index\", type=\"o\", add=T, col=c('salmon1'))\nmtext(\"Dynamic model residuals\", col=\"salmon1\", line=1, cex=1.25, adj = 0)\n\nhist(res.dynamic, col = \"cornsilk3\", xlab = \"Residuals of the dynamic model\", main=\"Density of the residuals\")\n\nqqnorm(res.fixed, ylab='Residuals', main = \"Q - Q plot for dynamic model\", col=\"cornflowerblue\")\ngrid()\nqqline(res.fixed)\n\n```\n\\hskip 15pt As we can see in figure 9 the residuals resemble a simmilar pattern as in the case with static panel models. Altough the quantile to quantile plot shows \"lighter\" tails than in the previous cases. \n\n\\newpage\n\n\\subsection{Conclusion of panel data models' analysis}\n\n\\hskip 15pt Based on the data and using static random effects ant fixed effects panel models we can conlude that the only significant variables to tourist arrivals' changes is changes to the average hours worked in a given country and the changes to taxes on goods. After using the feasible generalized least squares method we have gotten that an additional variable - terrorist attacks - is a significant variable to tourism flows as well. The significance of the hours worked and taxes variables can be explained that more hours worked and lower taxes would lead to more bussinesses and hence an increase in tourist attractions in a given country. On average, a one percent increase in hours worked would lead to an increase of 1.17 percent of tourist arrivals and a one percent increase in taxes to goods and services would decline the number of tourist arrivals by about 1.1 percent. Terrorist attacks have weak influence to the rate of change of tourist arrivals. One attack would lead to a decrease of about 0.02 percent of tourist flows. It would take about 50 additional attacks a year to lover tourist arrivals by 1 percent. This can be explainded that the services that prevent terrorism is doing a good job and the relative number of incidents are not that high to prevent tourists from visiting a country.\n\n\\hskip 15pt According to the dynamic model, the lag of one of the rate of change of tourist arrivals is also a significant variable which correlates positivelly with the changes in the present to tourist arrivals. A one percent increase to to the present tourism flows would lead to about 0.07 percent increase in tourism flows in the future.\n\n\\newpage\n\n\\subsection{Decomposition of flows models}\n\n\\hskip 15pt In this section a model which uses a more detailed flows of tourism data between the countries which were analyzed is created. This data can be obtained from the OECD database. A more detailed flows (or decomposition of flows) in this section means that there is information not only about total tourist arrivals but total arrivals from certain countries. For example, the United Kingdom's data for the year 2014:\n\n\\vskip 4pt\n\n\\centering\n\n```{r visualising structure data, echo=F}\n\nkable(struct[struct$Country==\"United Kingdom\" & struct$Date==\"2014\" & struct$Indicator %in% countries, ], format = \"latex\", row.names = F)\n\n```\n\\raggedright\n\n\\vskip 4pt\n\n\\hskip 15pt The downside is that that there are only available years from 2009 to 2014 (after differentiation). The matrices for a standart linear model are $Y$ and $X$ where:\n\n$Y_{ikt}$ - the total number of arrivals from country k to country i at time period t.\n\n$X_{itk}$ - both the domestic and abroad economy's GDP per capita, domestic terror attacks, domestic taxes on goods and services, domestic investment to infrastructure.\n\n\\hskip 15pt Our goal is to estimate $\\beta$ in:\n\n$$Y_{itk} = \\alpha +  X_{itk} \\beta + \\epsilon$$\n\n\\hskip 15pt The OLS procedure is used for this goal:\n\n$$ \\widehat{\\beta} = \\left( X^{T} X \\right)^{-1}X^{T}Y $$\n\n\n```{r structured panel data, echo=F, include=FALSE}\n\nsdt <- struct\nsdt <- sdt[!(sdt$Indicator %in% c(\"Other collective establishments\", \"Hotels and similar establishments\", \"Overnight visitors (tourists)\", \"Total international arrivals\", \"Same-day visitors (excursionists)\", \"Nights in all types of accommodation\", \n                                  \"Specialised establishments\", \"Private accommodation\")), ]\n\nsdt <- sdt[sdt$Country %in% unique(pdata$Country) & sdt$Indicator %in% unique(gdp$Country), ] %>% rename(c(\"Value\" = \"Arrivals\", \"Indicator\" = \"Origin\"))\n\nsdt.sub <- sdt\nsdt.sub <- ddply(sdt.sub, ~Country + Origin, function(xframe){\n  \n  xframe <<- xframe\n  if(dim(xframe)[1] >= 6){\n    \n    ## Adding variable for domestic economy\n    \n    xframe <- merge(xframe, gdp) %>% rename(c(\"value\" = \"gdp.d\"))\n    xframe$Indicator <- NULL\n    \n    ## Adding variable for foreign economy\n    \n    gdp.a <- gdp %>% filter(Country==xframe$Origin[1], Date %in% 2008:2014) %>% rename(c(\"value\" = \"gdp.a\"))\n    xframe$gdp.a <- gdp.a[, \"gdp.a\"]\n    \n    ## Adding hours worked \n\n    h <- hours %>% filter(Country==xframe$Country[1], Date %in% 2008:2014) %>% rename(c(\"Value\" = \"hours.worked\"))\n    xframe$hours <- h[, \"hours.worked\"]\n\n    ## Adding terror attacks\n    \n    ter <- terror %>% filter(Country==xframe$Country[1], Date %in% 2008:2014)\n    xframe$terror <- ter[, \"Terror.attacks\"]\n    \n    ## Adding taxes\n    \n    taxes <- tax %>% filter(Country==xframe$Country[1], Date %in% 2008:2014) %>% rename(c(\"Value\" = \"taxes\"))\n    xframe$taxes <- taxes[, \"taxes\"]\n    \n   ## Adding investments\n    \n    Invest <- Inv %>% filter(Country==xframe$Country[1], Date %in% 2008:2014) %>% rename(c(\"Value\" = \"Investment\"))\n    xframe$Investment <- Invest[, \"Investment\"]\n  \n    \n    xframe$hours <- c(NA, diff(log(xframe$hours)))\n    xframe$gdp.d <- c(NA, diff(log(xframe$gdp.d)))\n    xframe$gdp.a <- c(NA, diff(log(xframe$gdp.a)))\n    xframe$Arrivals <- c(NA, diff(log(xframe$Arrivals))) \n    xframe$terror <- c(NA, diff(xframe$terror)) \n    xframe$taxes  <- c(NA, diff(xframe$taxes))\n    xframe$Investment  <- c(NA, diff(xframe$Investment))\n    \n  }\n  \n    return(xframe)\n})\n\nsdt.sub$Origin <- NULL\nsdt.sub <- sdt.sub[complete.cases(sdt.sub), ]\n\nmodel.ols <-  lm(Arrivals ~  gdp.a + gdp.d + terror + hours + taxes + Investment, data=sdt.sub)\n\n```\n\n\\hskip 15pt The structure of Y is (only the first 5 rows of Y):\n\n\n```{r visualising structure data Y, echo=F}\n\nkable(sdt.sub[1:5, c(1:3)])\n\n```\n\n\\hskip 15pt The $Country$ and $Date$ are added just for clarification.\n\n\\hskip 15pt The structure of X is (only the first 5 rows of X):\n\n```{r visualising structure data X, echo=F}\n\ndttt <- cbind(rep.int(1, 5), sdt.sub[1:5, c(4:9)])\nnames(dttt)[1] <- \"Intercept\"\nkable(dttt)\n\n```\n  \n\\hskip 15pt The X is a matrix of 7 collumns (intercept collumn and the economic variables) and has the same number of rows as Y.\n\n```{r, results='asis', echo=F, warning=F}\n\ntab <- xtable(summary(model.ols)$coef, digits=c(3, 3, 3, 3, 3), caption = \"OLS model\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n```\n\n\\hskip 15pt As we can see from table 13, the only significant variables are GDP per capita abroad and hours worked domestically (with significance level of 0.1).\n\n```{r, results='asis', echo=F, warning=F}\n\nmodel.ols <-  lm(Arrivals ~  gdp.a +  hours, data=sdt.sub)\ntab <- xtable(summary(model.ols)$coef, digits=c(3, 3, 3, 3, 3), caption = \"Final OLS model\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\n\\hskip 15pt The terror attacks variable is not significant thus meaning that there is no spill-over effect in the countries which were analyzed. What is more interesting is that the number of tourist arrivals does not depend on the local economy but rather on the economic states of countries from which there are visitors. A one percent change in GDP of a country from which tourists are arriving leads to an increase of 0.343 percent in positive change to tourist arrivals.\n\n\\newpage\n\n\\subsection{Residual analysis}\n\n```{r distribution of residuals of final model, echo=F, fig.cap=\"Distribution of the residuals\", fig.height=7, fig.width=8,  fig.pos=\"h\"}\n  \npar(mfrow=c(2,1))\n\nres <- residuals(model.ols)\n\nhist(res, col = \"cornsilk3\", xlab = \"Residuals of the structure model\", main=\"Density of the residuals\")\n\nqqnorm(res, ylab='Residuals', main = \"Q - Q plot for structure model\", col=\"cornflowerblue\")\ngrid()\nqqline(res)\n\n```\n\n\\hskip 15pt As we can see from figure 10 we can conclude that the residuals from the structure model graphically look the most normal out of all the models in this analysis so far.\n\n```{r cooks distance, echo=F, fig.cap=\"Inspecting for outliers\", fig.height=7, fig.width=7,  fig.pos=\"h\"}\n\npar(mfrow=c(2, 1))  \nplot(model.ols, 4, col=\"salmon1\", lwd=2)\nabline(h=4/nrow(sdt.sub), col=\"dodgerblue1\", lwd=2)\nlegendary2(col=\"dodgerblue1\", \"4/number of obs.\")\ngrid()\n\nc.dist <- cooks.distance(model.ols)\nr <- stdres(model.ols)\nplot(r, type=\"l\", xlab=\"number of obs.\", ylab=\"Residaul\", main=\"Plot of standartized residuals\", col=\"salmon1\")\nabline(h=3*sd(r), col=\"dodgerblue1\", lwd=2)\nabline(h=-3*sd(r), col=\"dodgerblue1\", lwd=2)\nlegendary2(col=\"dodgerblue1\", \"3 sigmas\")\ngrid()\n\n```\n\n\\hskip 15pt We can clearly see from figure 11 that there are some observations which cook's distance is much larger than the generally accepted rule of 4 divided by the number of observations. These points are eliminated from our data set. \n\n\n```{r model without influantial points, results='asis', echo=F, warning=F}\n  \nsdt.sub$res <- abs(r)\nsdt.sub <- sdt.sub[sdt.sub$res<2.5, ]\nmodel.ols <- lm(Arrivals ~  gdp.a + gdp.d + terror + hours + taxes + Investment, data=sdt.sub)\ntab <- xtable(summary(model.ols)$coef, digits=c(3, 3, 3, 3, 3), caption = \"OLS model without the influential points\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\n\\hskip 15pt Eliminating the influential points and re-regressed the model we got that the variable hours worked is not significant. Also we can see that from figure 12 that the residuals are visually normal. The Shapiro-Wilk test's statistic is 0.039 which with alpha level of 0.01 would imply normality.\n\n```{r distribution of residuals of final model 2, echo=F, fig.cap=\"Distribution of the residuals without influential points\", fig.height=7, fig.width=7,  fig.pos=\"h\"}\n\nmodel.ols <-  lm(Arrivals ~  gdp.a, data=sdt.sub)    \npar(mfrow=c(2,1))\n\nres <- residuals(model.ols)\n\nhist(res, col = \"cornsilk3\", xlab = \"Residuals of the structure model\", main=\"Density of the residuals\")\n\nqqnorm(res, ylab='Residuals', main = \"Q - Q plot for structure model\", col=\"cornflowerblue\")\ngrid()\nqqline(res)\n\n```\n\n```{r, results='asis', echo=F, warning=F}\n\nmodel.ols <-  lm(Arrivals ~  gdp.a, data=sdt.sub)\ntab <- xtable(summary(model.ols)$coef, digits=c(3, 3, 3, 3, 3), caption = \"Final OLS model without influential points\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\n\\hskip 15pt The final linear model is in table 16.\n\n\\newpage\n\n\\subsection{Fixed effects panel model for decomposed flows}\n\n\\hskip 15pt In this section a panel model for the more detailed data of the tourism flows is created. In order to do this we will breating a new $\\textit{id}$ variable which will be unique to all countries - origin pairs. For example, the head of our data:\n\n```{r decomposed panel data, echo=F, include=FALSE}\n\nsdt <- struct\nsdt <- sdt[!(sdt$Indicator %in% c(\"Other collective establishments\", \"Hotels and similar establishments\", \"Overnight visitors (tourists)\", \"Total international arrivals\", \"Same-day visitors (excursionists)\", \"Nights in all types of accommodation\", \n                                  \"Specialised establishments\", \"Private accommodation\")), ]\n\nsdt <- sdt[sdt$Country %in% unique(pdata$Country) & sdt$Indicator %in% unique(gdp$Country), ] %>% rename(c(\"Value\" = \"Arrivals\", \"Indicator\" = \"Origin\"))\n\nsdt <- sdt[sdt$Country %in% countries & sdt$Origin %in% countries, ]\nsdt.sub <- sdt\nsdt.sub <- ddply(sdt.sub, ~Country + Origin, function(xframe){\n  \n  xframe <<- xframe\n  \n  if(dim(xframe)[1] >= 6){\n    \n    ## Adding terror attacks\n    \n    ter <- terror %>% filter(Country==xframe$Country[1], Date %in% 2008:2014)\n    xframe$terror <- ter[, \"Terror.attacks\"]\n    \n    ## Adding terror abroad\n    \n    ter.a <- terror %>% filter(Country==xframe$Origin[1], Date %in% 2008:2014)\n    if(dim(ter.a)[1]==0){\n      \n      xframe$terror.abroad <- NA\n      \n    } else {\n      \n      xframe$terror.abroad <- ter.a[, \"Terror.attacks\"]\n    }\n    \n    ## Adding GDP abroad and GDP domestic\n    \n    xframe <- merge(xframe, gdp) %>% rename(c(\"value\" = \"gdp.d\"))\n    xframe$Indicator <- NULL\n    \n    \n    gdp.a <- gdp %>% filter(Country==xframe$Origin[1], Date %in% 2008:2014) %>% rename(c(\"value\" = \"gdp.a\"))\n    xframe$gdp.a <- gdp.a[, \"gdp.a\"]\n    \n    ## Adding hours worked domestic\n\n    h <- hours %>% filter(Country==xframe$Country[1], Date %in% 2008:2014) %>% rename(c(\"Value\" = \"hours.worked\"))\n    xframe$hours <- h[, \"hours.worked\"]\n\n    ## Adding hours abroad\n    \n    h <- hours %>% filter(Country==xframe$Origin[1], Date %in% 2008:2014) %>% rename(c(\"Value\" = \"hours.worked\"))\n    xframe$hours.abroad <- h[, \"hours.worked\"]\n    \n    ## Adding taxes\n    \n    taxes <- tax %>% filter(Country==xframe$Country[1], Date %in% 2008:2014) %>% rename(c(\"Value\" = \"taxes\"))\n    xframe$taxes <- taxes[, \"taxes\"]\n    \n    xframe$Arrivals <- c(NA, diff(log(xframe$Arrivals))) \n    xframe$terror <- c(NA, diff(xframe$terror)) \n    xframe$terror.abroad <- c(NA, diff(xframe$terror.abroad)) \n    xframe$gdp.d <- c(NA, diff(log(xframe$gdp.d))) \n    xframe$gdp.a <- c(NA, diff(log(xframe$gdp.a))) \n    xframe$hours <- c(NA, diff(log(xframe$hours))) \n    xframe$hours.abroad <- c(NA, diff(log(xframe$hours.abroad))) \n    xframe$taxes <- c(NA, diff(xframe$hours.abroad)) \n    \n    \n  }\n  \n    return(xframe)\n})\n\nsdt.sub$id <- paste(sdt$Country, \"+\", sdt$Origin)\nsdt.sub$Origin <- NULL\nsdt.sub$Country <- NULL\nsdt.sub <- sdt.sub[, c(\"id\", \"Date\", \"Arrivals\", \"terror\", \"terror.abroad\", \"gdp.d\", \"gdp.a\", \"hours\", \"hours.abroad\", \"taxes\")]\n\nsdt.sub <- sdt.sub[complete.cases(sdt.sub), ]\n\nmodel.ols <-  lm(Arrivals ~  terror + terror.abroad + gdp.a + gdp.d + hours + hours.abroad + taxes, data=sdt.sub)\nr <- stdres(model.ols)\nsdt.sub$res <- abs(r)\nsdt.sub <- sdt.sub[sdt.sub$res<2.5, ]\n```\n```{r visualising the new data structure, echo=F}\n\nkable(head(sdt.sub[,1:6]))\n\n```\n\n\\hskip 15pt Note that only 6 first six collumns are displayed. We have a data set of 245 data points and will be creating a model:\n\n$$ Y_{it}= f(terror_{it}, terror.abroad_{it}, gdp.a_{it}, gdp.d_{it}, hours_{it}, hours.abroad_{it}, tax_{it}) + \\epsilon_{it} $$\n\\hskip 15pt The variables are the ones which were used up to this point in this thesis:\n\n$gdp$ - the differences of logs of gdp per capita. \n\n$terror$ - changes in terror attacks. \n\n$hours$ - changes of logs in the annual mean hours worked\n\n$tax$ - changes in the taxes of goods and services. Note that we will exclude the taxes in abroad countries.\n\n\\newpage\n\n\\hskip 15pt The difference now is that the $Y_{it}$ variable is not a certain country but the pair $destination + origin$ which means that every coordinate of the $Y$ variable is the percentage change of tourism flows from the origin country to the destination country.  \n\n```{r new fied effect, echo=F}\n\npdata2 <- plm.data(sdt.sub, indexes = c(\"id\", \"Date\"))\nmodel.fixed2 <- pggls(Arrivals ~ terror + terror.abroad + gdp.d + gdp.a + hours + hours.abroad + taxes, data=pdata2, \n                   model = \"within\")\n\n```\n\n```{r, results='asis', echo=F, warning=F}\n\ntab <- xtable(summary(model.fixed2)$CoefTable, digits=c(3, 3, 3, 3, 3), caption = \"Initial fixed effects model with decomposed flows\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\n```{r final fixed effect, echo=F}\n\nmodel.fixed2 <- pggls(Arrivals ~ gdp.a, data=pdata2, \n                   model = \"within\")\n```\n\n```{r, results='asis', echo=F, warning=F}\n\ntab <- xtable(summary(model.fixed2)$CoefTable, digits=c(3, 3, 3, 3, 3), caption = \"Final fixed effects model with decomposed flows\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\n\\hskip 15pt As we can see from table 19 the only significant variable left is the GDP abroad variable. A one percent increase in the GDP abroad would lead to an increase of 0.17 percent of tourist flows. \n\n\\newpage\n\n\\section{All main models}\n\n\\hskip 15pt In this thesis 4 main models with cross-sectional panel data were created:\n\n```{r all models, results='asis', echo=F, warning=F}\n\n# tab <- xtable(summary(model.fixed.gg)$CoefTable, digits=c(4, 4, 4, 4, 4), caption = \"Final fixed effects model\")\n# print(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n# \n# tab <- xtable(suppressWarnings(summary(model.dynamic)$coef), digits=c(4, 4, 4, 4, 4), caption = \"Final dynamic panel data model\")\n# print(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\ntab <- matrix(ncol=5, nrow=5) %>% as.data.frame\ncolnames(tab) <- c(\"Variable\", \"Dynamic\", \"Fixed effects robust\",  \"Fixed effects\" , \"Random effects\")\ntab$Variable <- c(\"Lag of tourism\", \"Hours worked\", \"Terror attacks\", \"Taxes\", \"R squared\")\ntab$Dynamic <- c(\"0.072 (0.051)\", \"1.213 (0.351)\", \"-0.0001 (0.006)\", \"-0.011 (0.073)\", \"0.199\")\ntab$`Fixed effects robust` <- c(\"\", \"1.171 (<0.001)\", \"-0.0019 (<0.001)\", \"-0.011 (<0.001)\", \"0.145\")\ntab$`Fixed effects` <- c(\"\", \"1.02 (0.008)\", \"-0.0001 (0.156)\", \"-0.009 (0.007)\", \" 0.027298\")\ntab$`Random effects` <- c(\"\", \"0.972 (0.010)\", \"\", \"-0.009 (0.009)\", \"0.07673\")  \n\n# tab$`Lag of tourism` <- c(\"0.072 (0.051)\", \"\", \"\", \"\")\n# tab$`hours worked` <- c(\"1.213 (0.351)\", \"1.171 (<0.001)\",  \"1.02 (0.008)\", \"0.972 (0.010)\")\n# tab$`terror attacks` <- c(\"-0.0012 (0.006)\", \"-0.0019 (<0.001)\", \"-0.0001 (0.156)\", \"\")\n# tab$taxes <- c(\"-0.011 (0.073)\",  \"-0.011 (<0.001)\", \"-0.009 (0.007)\", \"-0.009 (0.009)\")\n# tab$`R squared` <- c(\"0.199\", \"0.145\", \" 0.027298\", \"0.07673\")\n\n# tab <- t(tab) %>% as.data.frame()\n\ntab <- xtable(tab, caption = \"Table of all the main models\")\nprint(tab, digits=c(4, 4, 4, 4, 4), type=\"latex\", floating = T, only.contents = F, comment = F, row.names = F)\n\n```\n\n\\hskip 15pt The number in the brackets is the p-value of the coeffcient. The final model should be picked between the robust fixed effects model and the dynamic panel model. Because of the very similar coefficient values between these two models but the dynamic model offering an additional variable in the lags of tourism flows we will hold that this is the final model and we will base the conclusions based on it.\n\n\\hskip 15pt The model with the decomposed tourism flows data:\n\n\\centering\n\n```{r all models addition, results='asis', echo=F, warning=F}\n\ntab <- xtable(summary(model.fixed2)$CoefTable, digits=c(4, 4, 4, 4, 4), caption = \"Final fixed effects model with decomposed flows\")\nprint(tab, type=\"latex\", floating = T, only.contents = F, comment = F)\n\n```\n\n\\raggedright\n\n\\newpage\n\n\\section{Conclusion}\n\n\\hskip 15pt Based on the dynamic panel model which was created using public annual data we can make several conclusions on the tourism flows in the western countries:\n\n\\hskip 15pt $\\bullet$ GDP per capita changes in a given country do not influence tourist arrivals to that country.\n\n\\hskip 15pt $\\bullet$ Percentage change of taxes on goods and services in country i influences the rate of change in tourist arrivals. A 1 percent increase to taxes on goods and services would lead to a decline of about 1.12 percent in tourist arrivals. \n\n\\hskip 15pt $\\bullet$ Percentage change of investments to infrastructure in country i influences the rate of change in tourist arrivals. But the sign near the coefficient was negative in all of the models which would imply that a positive change in investments would lead to a decline in tourist arrivals. Hence we dropped this variable from our final model. \n\n\\hskip 15pt $\\bullet$ Percentage change in annual hours worked has a significant influence to the percentage change of tourist arrivals. A one percent increase in hours worked annually would increase the tourism flows by about 1.21 percent.  \n\n\\hskip 15pt $\\bullet$ The dynamic panel model showed that the lag of one of the rate of change in tourist arrivals has a significant impact to the current rate of tourist arrivals. A one percent increase in tourist arrivals would result in an additional growth of about 0.072 percent of tourist arrivals in the future. \n\n\\hskip 15pt $\\bullet$ Terrorism has a significant but a weak in absolute sense effect to tourism flows. One terror attack in a given country would lead to a decline of 0.012 percent of the tourism flows.\n\n\\hskip 15pt Based on the decomposed data of the tourism flows from the OECD data base:\n\n\\hskip 15pt $\\bullet$ The domestic GDP per capita changes have no significant effect to the percentage changes in tourist arrivals.\n\n\\hskip 15pt $\\bullet$ The most significant variable regarding the percentage change in tourist arrivals to country i is the percentage change in GDP per capita in abroad countries from whom the tourists come to the country i. A one percent increase in foreign economies leads to about 0.17 percentage increase in tourist arrivals.\n\n\n\\newpage\n\n# References\n\n```{r references, results=\"asis\", echo=F, warning=F}\n# PrintBibliography(bib, .opts = list(bib.style = \"numeric\"))\nPrintBibliography(bib)\n```\n\n\\newpage\n\n<!-- \\section{Tests} -->\n\n<!-- \\subsection{F test} -->\n\n<!-- The f test `r Cite(bib, 'F.test', .opts = list(cite.style = \"numeric\"), after=\" , pp. 3-4\")` that is used with the panel models in R statistical package tests the following hypothesis: assume that we have two models:  -->\n\n<!-- restricted -->\n<!-- $$y_{it} = \\alpha +  X_{it} \\beta + \\epsilon_{it}$$ -->\n<!-- and unrestricted: -->\n\n<!-- $$y_{it} = \\alpha + u_{i} +  X_{it} \\beta + \\epsilon_{it}$$ -->\n\n<!-- Then the hypothesis is  -->\n\n\n<!-- \\[\\begin{array}{lr} -->\n<!--         H_{0}: u_{i} =0,  \\forall i \\\\ -->\n<!--         H_{1}: \\exists i:    u_{i} \\neq 0,   -->\n<!--         \\end{array}\\] -->\n\n<!-- The alternative hypothesis would mean that there exists a country where adding the term $u_{i}$ the r-squared statistic increases.  -->\n\n<!-- To test this hypothes we use the F statistic (hence the name of the test): -->\n\n<!-- $$F = \\dfrac{(ESS_{R} - ESS_{U})/(N- 1) }{ESS_{U}/((T-1)N- K)}$$ -->\n\n<!-- Where  -->\n\n<!-- $ESS_{U}$ - error sum of squares of the unrestricted model -->\n\n<!-- $ESS_{R}$ - error sum of squares of the restricted model -->\n\n<!-- $N$ - number of countries -->\n\n<!-- $T$ - number of time periods -->\n\n<!-- Under the assumption that the residuals are gaussian then the F statistic is distributed by the $\\textbf{F}$ distribution with N-1, N(T-1) - K degrees of freedom. -->\n\n<!-- \\newpage -->\n\n\\appendix\n\n\\section{Appendix 1: Hausman test for panel models}\n\n\\hskip 15pt The Hausman test `r Cite(bib, 'Hausman.test', .opts = list(cite.style = \"numeric\"), after=\" , pp. 39-40\")` is used to determine whether $X_{it}$ are uncorrelated with $\\alpha_{i}$. To test this we denote two estimators:\n\n$\\widehat{\\beta_{FE}}$ - fixed effects estimate. \n\n$\\widehat{\\beta_{RE}}$ - random effects estimate.\n\nThe hypothesis is then:\n\n Estimator                $H_{0}$ holds              $H_{0}$ is rejected  \n-------                  -------------              -----------------\n$\\widehat{\\beta_{RE}}$    consistent;                 Inconsistent\n                          efficient\n$\\widehat{\\beta_{FE}}$    consistent;                  consistent       \n                          inefficient\n\n-------                  -------------              -----------------\n\n\n\\hskip 15pt Since under null hypothesis $\\widehat{\\beta_{RE}}$ is efficient then \n\n$$Var(\\widehat{\\beta_{FE}} - \\widehat{\\beta_{RE}}) =Var(\\widehat{\\beta_{FE}}) - Var(\\widehat{\\beta_{RE}})$$\n\\hskip 15pt Then the Hausman statistic is defined as:\n\n$$H = \\left( \\widehat{\\beta_{FE}} - \\widehat{\\beta_{RE}} \\right) ^{T} \\left(Var(\\widehat{\\beta_{FE}}) - Var(\\widehat{\\beta_{RE}})\\right) \\left( \\widehat{\\beta_{FE}} - \\widehat{\\beta_{RE}} \\right)$$\n\nand \n\n$$H \\overset{asy}{\\sim} \\chi^2$$\n\n\\hskip 15pt The main idea of this test is that if $Var(\\widehat{\\beta_{FE}})$ is smaller than  $Var(\\widehat{\\beta_{RE}})$ it means that the H statistic will be \"large\" and the null hypothesis will be rejected. This in turn means that $\\widehat{\\beta_{RE}}$ is no efficient because there exists another statistic with a smaller variance.\n\n\\newpage\n\n\\section{Appendix 2: Ljung-Box test}\n\n\\hskip 15pt The Ljung-Box test is used for detecting serial autocorrelation in the series. The test's hypothesis is:\n\n\\[\\begin{array}{lr}\n       H_{0}: \\text{The data is independently distributed} \\\\\n        H_{1}: \\text{The data is not independently distributed; it exhibits serial correlation.},  \n        \\end{array}\\]\n\n\\hskip 15pt To test this hypothesis the following statistic is used:\n\n$$Q = n(n +2) \\sum^{h}_{k=1} \\left( \\dfrac{\\rho^{2}_{k}}{n - k} \\right)$$\n\nWhere\n\n$\\rho^{2}_{k}$ - is the sample autocorrelation at lag k.\n\n$n$ - the number of observations.\n\n$k$ - the lag. \n\n$h$ - number of lags beeing tested.\n\n\\hskip 15pt This statistic (under $H_{0}$) is distributed by the $\\tilde{\\chi}^2_{h}$ distribution. \n\n\\newpage\n\n\\section{Appendix 3: Scatter diagrams}\n\n```{r,echo=F, fig.cap=\"GDP per capita vs total arrivals\", fig.height=9, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n \npar(mfrow=c(4, 3))\n\nfor(cn in unique(pdata$Country)){\n  \n  grid.frame(x=pdata$gdp, y=pdata$Total.Arrivals, xlab=\"GDP per capita\", ylab=\"Total arrivals\")\n  matplot(x=pdata[pdata$Country==cn, \"gdp\"], y=pdata[pdata$Country==cn, \"Total.Arrivals\"], type=\"p\", pch=19, add=T, col=\"blue\")\n  model <- lm(Total.Arrivals ~ gdp, data=pdata[pdata$Country==cn, ])\n  abline(model, col=\"red\")\n  info <- summary(model)$coefficients\n  p.val <- info[, \"Pr(>|t|)\"][2]\n  legendary2(\"Regression line\", col=\"red\")\n  mtext(cn, adj=0, line=2, cex=1.2, col=\"dodgerblue1\")\n  mtext(paste(\"p - value for regressor:\", round(as.numeric(p.val), 3)), line=1, adj=0, col=\"salmon1\")\n  \n}\n\n\n```\n\n\n```{r , echo=F, fig.cap=\"Hours worked vs total arrivals\", fig.height=10, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n \npar(mfrow=c(4, 3))\n\nfor(cn in unique(pdata$Country)){\n  \n  grid.frame(x=pdata$hours.worked, y=pdata$Total.Arrivals, xlab=\"Hours worked\", ylab=\"Total arrivals\")\n  matplot(x=pdata[pdata$Country==cn, \"hours.worked\"], y=pdata[pdata$Country==cn, \"Total.Arrivals\"], type=\"p\", pch=19, add=T, col=\"blue\")\n  model <- lm(Total.Arrivals ~ hours.worked, data=pdata[pdata$Country==cn, ])\n  abline(model, col=\"red\")\n  info <- summary(model)$coefficients\n  p.val <- info[, \"Pr(>|t|)\"][2]\n  legendary2(\"Regression line\", col=\"red\")\n  mtext(cn, adj=0, line=2, cex=1.2, col=\"dodgerblue1\")\n  mtext(paste(\"p - value for regressor:\", round(as.numeric(p.val), 3)), line=1, adj=0, col=\"salmon1\")\n  \n}\n\n\n```\n\n\n```{r, echo=F, fig.cap=\"Relationship between changes in terror attacks and number of arrivals\", fig.height=10, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n\nppdata <- pdata[abs(pdata$Terror.attacks)<100,  ]\n \npar(mfrow=c(4, 3))\n\nfor(cn in unique(pdata$Country)){\n  \n  grid.frame(x=ppdata$Terror.attacks, y=ppdata$Total.Arrivals, xlab=\"Terror attacks\", ylab=\"Total arrivals\")\n  matplot(x=ppdata[ppdata$Country==cn, \"Terror.attacks\"], y=ppdata[ppdata$Country==cn, \"Total.Arrivals\"], type=\"p\", pch=19, add=T, col=\"blue\")\n  model <- lm(Total.Arrivals ~ Terror.attacks, data=ppdata[ppdata$Country==cn, ])\n  abline(model, col=\"red\")\n  info <- summary(model)$coefficients\n  p.val <- info[, \"Pr(>|t|)\"][2]\n  legendary2(\"Regression line\", col=\"red\")\n  mtext(cn, adj=0, line=2, cex=1.2, col=\"dodgerblue1\")\n  mtext(paste(\"p - value for regressor:\", round(as.numeric(p.val), 3)), line=1, adj=0, col=\"salmon1\")\n  \n}\n\n```\n\n\n```{r ,  echo=F, fig.cap=\"Infrastructure vs total arrivals\", fig.height=10, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n \npar(mfrow=c(4, 3))\n\nfor(cn in unique(pdata$Country)){\n  \n  grid.frame(x=pdata$Investment, y=pdata$Total.Arrivals, xlab=\"Investment to infrastructure\", ylab=\"Total arrivals\")\n  matplot(x=pdata[pdata$Country==cn, \"Investment\"], y=pdata[pdata$Country==cn, \"Total.Arrivals\"], type=\"p\", pch=19, add=T, col=\"blue\")\n  model <- lm(Total.Arrivals ~ Investment, data=pdata[pdata$Country==cn, ])\n  abline(model, col=\"red\")\n  info <- summary(model)$coefficients\n  p.val <- info[, \"Pr(>|t|)\"][2]\n  legendary2(\"Regression line\", col=\"red\")\n  mtext(cn, adj=0, line=2, cex=1.2, col=\"dodgerblue1\")\n  mtext(paste(\"p - value for regressor:\", round(as.numeric(p.val), 3)), line=1, adj=0, col=\"salmon1\")\n  \n}\n\n\n```\n\n```{r , echo=F,  fig.cap=\"Taxes vs total arrivals\", fig.height=10, fig.width=8,  fig.pos=\"!ht\", fig.align=\"center\"}\n \npar(mfrow=c(4, 3))\n\nfor(cn in unique(pdata$Country)){\n  \n  grid.frame(x=pdata$tax, y=pdata$Total.Arrivals, xlab=\"Taxes on goods on services\", ylab=\"Total arrivals\")\n  matplot(x=pdata[pdata$Country==cn, \"tax\"], y=pdata[pdata$Country==cn, \"Total.Arrivals\"], type=\"p\", pch=19, add=T, col=\"blue\")\n  model <- lm(Total.Arrivals ~ tax, data=pdata[pdata$Country==cn, ])\n  abline(model, col=\"red\")\n  info <- summary(model)$coefficients\n  p.val <- info[, \"Pr(>|t|)\"][2]\n  legendary2(\"Regression line\", col=\"red\")\n  mtext(cn, adj=0, line=2, cex=1.2, col=\"dodgerblue1\")\n  mtext(paste(\"p - value for regressor:\", round(as.numeric(p.val), 3)), line=1, adj=0, col=\"salmon1\")\n  \n}\n\n\n```\n\n\n\n\n\n\n",
    "created" : 1501341759256.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1606583681",
    "id" : "F39FBEA7",
    "lastKnownWriteTime" : 1501358062,
    "last_content_update" : 1501358062256,
    "path" : "C:/Users/Eligijus/Desktop/bakalauras/bachelor/code.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}